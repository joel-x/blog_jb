{
  "hash": "ee64b3d82463decfb91b7845f8f36407",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Churn Rate (Tasa de Abandono)\nauthor: Joel Burbano\ndate: 08-27-2024\ncategories: [R, Machine Learning]\n---\n\n\n\nEn este proyecto vamos a desarrollar un  modelo predictivo para identificar clientes con alto riesgo de churn\n(abandono) en una institución bancaria, utilizando técnicas de Machine Learning \n\n# Importación de Datos\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Importamos las librerias\nlibrary(data.table)\nlibrary(tidyverse)\nsource(\"D:/Joel/Blog/recursos/funciones_aux.R\")\ndf <- fread(\"Churn_Modelling.csv\")\nhead(df,5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   RowNumber CustomerId  Surname CreditScore Geography Gender   Age Tenure\n       <int>      <int>   <char>       <int>    <char> <char> <num>  <int>\n1:         1   15634602 Hargrave         619    France Female    42      2\n2:         2   15647311     Hill         608     Spain Female    41      1\n3:         3   15619304     Onio         502    France Female    42      8\n4:         4   15701354     Boni         699    France Female    39      1\n5:         5   15737888 Mitchell         850     Spain Female    43      2\n     Balance NumOfProducts HasCrCard IsActiveMember EstimatedSalary Exited\n       <num>         <int>     <int>          <int>           <num>  <int>\n1:      0.00             1         1              1       101348.88      1\n2:  83807.86             1         0              1       112542.58      0\n3: 159660.80             3         1              0       113931.57      1\n4:      0.00             2         0              0        93826.63      0\n5: 125510.82             1        NA              1        79084.10      0\n```\n\n\n:::\n:::\n\n\n\nbreve revisión a la variable dependiente\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf[, .N, by = Exited]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Exited     N\n    <int> <int>\n1:      1  2038\n2:      0  7964\n```\n\n\n:::\n:::\n\n\n\nNotamos que la data esta desbalanceada con el grupo mayoritario 1 que son las personas que abandonan\n\n* 0 No abandona\n* 1 Abandona\n\n# Particionamos la data en conjuntos Train / Test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base de modelamiento / validacion\nset.seed(95)\nmarca <- sample(1:nrow(df), size = floor(0.7 * nrow(df)), replace = FALSE)\ndf[, ModVal := 1:nrow(df)]\ndf[, ModVal := ifelse(ModVal %in% marca, 0, 1)]\ndf[, .N, by = ModVal]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ModVal     N\n    <num> <int>\n1:      1  3001\n2:      0  7001\n```\n\n\n:::\n\n```{.r .cell-code}\ndf[, table(Exited, ModVal, useNA = \"always\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      ModVal\nExited    0    1 <NA>\n  0    5548 2416    0\n  1    1453  585    0\n  <NA>    0    0    0\n```\n\n\n:::\n:::\n\n\n# Análisis Exploratorio \n\n## Tipo de datos\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'data.table' and 'data.frame':\t10002 obs. of  15 variables:\n $ RowNumber      : int  1 2 3 4 5 6 7 8 9 10 ...\n $ CustomerId     : int  15634602 15647311 15619304 15701354 15737888 15574012 15592531 15656148 15792365 15592389 ...\n $ Surname        : chr  \"Hargrave\" \"Hill\" \"Onio\" \"Boni\" ...\n $ CreditScore    : int  619 608 502 699 850 645 822 376 501 684 ...\n $ Geography      : chr  \"France\" \"Spain\" \"France\" \"France\" ...\n $ Gender         : chr  \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ Age            : num  42 41 42 39 43 44 50 29 44 NA ...\n $ Tenure         : int  2 1 8 1 2 8 7 4 4 2 ...\n $ Balance        : num  0 83808 159661 0 125511 ...\n $ NumOfProducts  : int  1 1 3 2 1 2 2 4 2 1 ...\n $ HasCrCard      : int  1 0 1 0 NA 1 1 1 0 1 ...\n $ IsActiveMember : int  1 1 0 0 1 0 1 0 NA 1 ...\n $ EstimatedSalary: num  101349 112543 113932 93827 79084 ...\n $ Exited         : int  1 0 1 0 0 1 0 1 0 0 ...\n $ ModVal         : num  1 0 0 0 0 0 1 0 0 1 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n\n\n:::\n:::\n\n\ncreamos una lista de variables para mejor manipulación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindex <- c(\"RowNumber\", \"CustomerId\",\"Surname\")\nvar_num <- c(\"CreditScore\", \"Age\", \"Tenure\", \"Balance\",\"EstimatedSalary\")\nvar_cat <- setdiff(names(df),c(index,var_num,\"Exited\"))\n```\n:::\n\n\n\n## Cambio de nombres de las columnas\n\nEn esta ocasión no vamos a cambiar ningun nombre\n\n## Exploración de datos\n\nPrimero visualicemos un breve resumen de las variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   RowNumber       CustomerId         Surname           CreditScore   \n Min.   :    1   Min.   :15565701   Length:10002       Min.   :350.0  \n 1st Qu.: 2501   1st Qu.:15628525   Class :character   1st Qu.:584.0  \n Median : 5002   Median :15690732   Mode  :character   Median :652.0  \n Mean   : 5002   Mean   :15690933                      Mean   :650.6  \n 3rd Qu.: 7502   3rd Qu.:15753226                      3rd Qu.:718.0  \n Max.   :10000   Max.   :15815690                      Max.   :850.0  \n                                                                      \n  Geography            Gender               Age            Tenure      \n Length:10002       Length:10002       Min.   :18.00   Min.   : 0.000  \n Class :character   Class :character   1st Qu.:32.00   1st Qu.: 3.000  \n Mode  :character   Mode  :character   Median :37.00   Median : 5.000  \n                                       Mean   :38.92   Mean   : 5.012  \n                                       3rd Qu.:44.00   3rd Qu.: 7.000  \n                                       Max.   :92.00   Max.   :10.000  \n                                       NA's   :1                       \n    Balance       NumOfProducts    HasCrCard      IsActiveMember  \n Min.   :     0   Min.   :1.00   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:     0   1st Qu.:1.00   1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 97199   Median :1.00   Median :1.0000   Median :1.0000  \n Mean   : 76491   Mean   :1.53   Mean   :0.7055   Mean   :0.5149  \n 3rd Qu.:127648   3rd Qu.:2.00   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :250898   Max.   :4.00   Max.   :1.0000   Max.   :1.0000  \n                                 NA's   :1        NA's   :1       \n EstimatedSalary         Exited           ModVal   \n Min.   :    11.58   Min.   :0.0000   Min.   :0.0  \n 1st Qu.: 50983.75   1st Qu.:0.0000   1st Qu.:0.0  \n Median :100185.24   Median :0.0000   Median :0.0  \n Mean   :100083.33   Mean   :0.2038   Mean   :0.3  \n 3rd Qu.:149383.65   3rd Qu.:0.0000   3rd Qu.:1.0  \n Max.   :199992.48   Max.   :1.0000   Max.   :1.0  \n                                                   \n```\n\n\n:::\n:::\n\n\nNotamos que existen valores perdidos o NA's, los mismos que serán tratados mas adelante\n\n## Evaluación de valores nulos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tratamiento NA's \ndf <- df[!(is.na(HasCrCard) == TRUE),]\ndf <- df[!(is.na(IsActiveMember) == TRUE),]\ndf <- df[!(is.na(Age) == TRUE),]\nsum(is.na(df))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n## Valores duplicados\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- unique(df)\n```\n:::\n\n\n\n\n## Proporción del variable dependiente\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf[, round(.N / nrow(df),3), by = Exited]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Exited    V1\n    <int> <num>\n1:      1 0.204\n2:      0 0.796\n```\n\n\n:::\n:::\n\n\n\n# Seleccion de Variables (KS / VI)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# KS VI\n# Sujetos buenos y malos para calculo de KS\nmod <- df[ModVal == 0 & Exited %in% c(0,1)]\nval <- df[ModVal == 1]\n\n# identificación de variables con alto porcentaje de NA's\nporc <- sort(sapply(mod, porcNA), decreasing = TRUE)\nPorcentajeNA <- data.frame(names(porc), as.numeric(porc))\ncolnames(PorcentajeNA) <- c(\"Var\", \"Por\")\ndvars <- setdiff(colnames(mod), names(porc)[porc > 0.3])\n\n# tratamiento NA's \ndf <- df[!(is.na(HasCrCard) == TRUE),]\ndf <- df[!(is.na(IsActiveMember) == TRUE),]\n\nmod <- df[ModVal == 0 & Exited %in% c(0,1)]\nval <- df[ModVal == 1]\n\n# Identificación de variables constantes\ndvars <- dvars[!unname(unlist(sapply(mod[,dvars, with = FALSE], constante)))]\n\n\n# Ejecución de KS & VI\nvnum <- colnames(mod)[unname(sapply(mod, class)) %in% c(\"numeric\", \"integer\") ]\nvcat <- colnames(mod)[unname(sapply(mod, class)) %in% c(\"character\", \"logical\")]\ndnum <- mod[, vnum, with = FALSE]\ndcat <- mod[, vcat, with = FALSE]\nVI <- sort(sapply(dcat, TestVI, y = mod$Exited), decreasing = T)\ndVI <- data.frame(names(VI), VI)\ncolnames(dVI) <- c(\"Variable\", \"VI\"); rownames(dVI) <- NULL\ndVI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Variable          VI\n1 Geography  0.17789046\n2    Gender  0.05744401\n3   Surname -0.03811443\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculo de KS sobre variables numericas\nKS <- sapply(seq_along(dnum), function(i){TestKS(dnum[[i]], mod$Exited)})\ndKS <- data.frame(colnames(dnum), KS); dKS <- dKS[order(dKS$KS, decreasing = TRUE),]\ncolnames(dKS) <- c(\"Variable\", \"KS\"); rownames(dKS) <- NULL\ndKS\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Variable     KS\n1           Exited 1.0000\n2              Age 0.3790\n3    NumOfProducts 0.2163\n4   IsActiveMember 0.1945\n5          Balance 0.1528\n6      CreditScore 0.0460\n7       CustomerId 0.0222\n8        RowNumber 0.0217\n9  EstimatedSalary 0.0208\n10          Tenure 0.0169\n11       HasCrCard 0.0089\n12          ModVal 0.0000\n```\n\n\n:::\n:::\n\n\n\n\nSeleccionamos las variables con valores altos de KS / VI\n\n# Creación de Features para el modelo\n\n## Creación de features personalizada \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construcción de variables y discretización \n\ndf[,prbm_NumOfProducts := ifelse(NumOfProducts < 1.5, 0.2776061,\n                                 ifelse(NumOfProducts < 2.5, 0.0800000, 0.8744770))]\n\ndf[,prbm_Age := ifelse(Age < 42.5, 0.1208350,\n                       ifelse(Age < 46.5, 0.3450704,\n                              ifelse(Age < 57.5, 0.5261364, 0.3356808)))]\n\ndf[, prbm_IsActiveMember := ifelse(IsActiveMember < 0.5, 0.1451298,0.2732064)]\n\ndf[, prbm_Geography := ifelse(Geography == \"France\", 0.1667147,\n                              ifelse(Geography == \"Spain\",0.1624077, 0.3327684))]\ndf[, prbm_Balance := ifelse(Balance < 1884.5, 0.1368209, 0.2466209)]\n\ndf[, prbm_Gender := ifelse(Gender == \"Male\", 0.1714436 , 0.2507042)]\n\ndf[, prbm_CreditScore := ifelse(CreditScore <= 407.5, 0.94444444 ,0.20573066)]\n\ndf[, prbm_EstimatedSalary := ifelse(EstimatedSalary <= 25000, 0.2031063,\n                                    ifelse(EstimatedSalary <= 35000, 0.2156863,\n                                           ifelse(EstimatedSalary <= 60000, 0.1944134,\n                                                  ifelse(EstimatedSalary <= 75000, 0.2189239,\n                                                         ifelse(EstimatedSalary <= 85000, 0.1789474,\n                                                                ifelse(EstimatedSalary <= 155000, 0.1990913,\n                                                                       ifelse(EstimatedSalary <= 185000, 0.2301815, 0.1965649))))))  )]\n\n# Generación de muestras para el performance del modelo\nmod <- df[ModVal == 0 & Exited %in% c(0,1)]\nval <- df[ModVal ==1]\n```\n:::\n\n\n\n\n### Regresión Logística\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regresión logistica\nformula <- \"Exited ~\n  prbm_NumOfProducts +\n  prbm_Age +\n  prbm_IsActiveMember +\n  prbm_Geography + \n  prbm_Gender +\n  prbm_EstimatedSalary\n\"\nmodelo <- glm(formula = as.formula(formula), family = binomial(\"logit\"), data = mod)\nsummary(modelo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = as.formula(formula), family = binomial(\"logit\"), \n    data = mod)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)           -6.1860     0.6008 -10.296  < 2e-16 ***\nprbm_NumOfProducts     6.1156     0.2780  22.002  < 2e-16 ***\nprbm_Age               5.5137     0.2196  25.113  < 2e-16 ***\nprbm_IsActiveMember   -7.6616     0.5742 -13.343  < 2e-16 ***\nprbm_Geography         5.2643     0.4509  11.674  < 2e-16 ***\nprbm_Gender            5.9177     0.9004   6.572 4.95e-11 ***\nprbm_EstimatedSalary   6.3426     2.5981   2.441   0.0146 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7149.2  on 6997  degrees of freedom\nResidual deviance: 5134.2  on 6991  degrees of freedom\nAIC: 5148.2\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnom_vars <- all.vars(terms(modelo))[-1]\nres <- cor(setDT(mod)[, ..nom_vars])\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     prbm_NumOfProducts   prbm_Age prbm_IsActiveMember\nprbm_NumOfProducts          1.000000000 0.14015906         -0.03921337\nprbm_Age                    0.140159055 1.00000000          0.02311527\nprbm_IsActiveMember        -0.039213366 0.02311527          1.00000000\nprbm_Geography              0.076511468 0.06275108         -0.02691362\nprbm_Gender                 0.031159138 0.03948541         -0.02861081\nprbm_EstimatedSalary        0.004809131 0.01098787         -0.01646802\n                     prbm_Geography  prbm_Gender prbm_EstimatedSalary\nprbm_NumOfProducts       0.07651147  0.031159138          0.004809131\nprbm_Age                 0.06275108  0.039485408          0.010987871\nprbm_IsActiveMember     -0.02691362 -0.028610806         -0.016468018\nprbm_Geography           1.00000000  0.019422000          0.015802201\nprbm_Gender              0.01942200  1.000000000         -0.009303946\nprbm_EstimatedSalary     0.01580220 -0.009303946          1.000000000\n```\n\n\n:::\n\n```{.r .cell-code}\neigen(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\neigen() decomposition\n$values\n[1] 1.2103689 1.0254641 1.0085638 0.9703447 0.9400960 0.8451624\n\n$vectors\n            [,1]        [,2]        [,3]       [,4]        [,5]        [,6]\n[1,] -0.61329773  0.07464562  0.01739220  0.1542000  0.37626626  0.67278339\n[2,] -0.57690639  0.36902613  0.06410691 -0.1439743  0.24002392 -0.66973797\n[3,]  0.14872209  0.82019845  0.15353299 -0.3083363 -0.31987004  0.29016501\n[4,] -0.44372704 -0.11890199  0.16319040  0.3516848 -0.79861501 -0.02948562\n[5,] -0.25687639 -0.22070837 -0.60816689 -0.6674430 -0.24617892  0.09670143\n[6,] -0.07776557 -0.35024616  0.75862861 -0.5396852  0.01026557  0.06631192\n```\n\n\n:::\n\n```{.r .cell-code}\nsqrt( head(eigen(res)$values,1) / tail(eigen(res)$values,1)) # calculo IC > 5 indicios multicolinealidad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.19671\n```\n\n\n:::\n\n```{.r .cell-code}\ndf[, Y:= modelo$coefficients[1] + Reduce(`+`, Map(function(var, coef) get(var) * coef, names(modelo$coefficients[-1]), modelo$coefficients[-1]))]\ndf[, RL := (1 / (1 + exp(Y)))]\n#quantile(df$RL, probs = seq(0 , 1, by = 0.01), na.rm = TRUE)\n\nmod <- df[ModVal == 0 & Exited %in%  c(0,1)]\nval <- df[ModVal == 1]\n\n# Estimación  Probabilidades\nres_mod <- data.table(Var = mod$Exited, RL = mod$RL)\n\nres_val <- data.table(Var = val$Exited, RL = val$RL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráficas ROC\nlibrary(pROC)\nobjroc1 <- roc(res_mod$Var, res_mod$RL, auc=T, ci=T)\nplot(objroc1, col=\"blue\", xlab=\"1 - Especificidad\", ylab=\"Sensibilidad\", main=\"Comparación curvas ROC\", legacy.axes = TRUE)\nobjroc2 <- roc(res_val$Var, res_val$RL, auc=T, ci=T)\nplot(objroc2, col=\"red\", add=TRUE)\nlegend(\"bottomright\", legend=c(paste(\"Modelamiento\",round(objroc1$auc, 3)), paste(\"Validación\", round(objroc2$auc, 3))), col=c(\"blue\", \"red\"), lwd=0.5, title = \"AUC-ROC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#legend(\"topright\", legend = c(round(objroc1$auc, 3), round(objroc2$auc, 3)), col = c(\"blue\", \"red\"), lwd = 0.2 , title = \"AUC-ROC\")\n```\n:::\n\n\nCon estas features se ha alcanzado un AUC-ROC con la data de validación de 0.846\n\n\n## Optimal binning\n\nCreando los features y bins con la libreria `scorecard`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"scorecard\")\nlibrary(scorecard)\n\nvars <- c(\"NumOfProducts\", \"Age\", \"IsActiveMember\", \"Geography\", \"Gender\", \"EstimatedSalary\")\nbins <- woebin(df, y = \"Exited\", x = vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✔ Binning on 9998 rows and 7 columns in 00:00:02\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(bins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$NumOfProducts\n        variable      bin count count_distr   neg   pos   posprob        woe\n          <char>   <char> <int>       <num> <int> <int>     <num>      <num>\n1: NumOfProducts [-Inf,2)  5082   0.5083017  3673  1409 0.2772530  0.4043315\n2: NumOfProducts [2, Inf)  4916   0.4916983  4287   629 0.1279496 -0.5567511\n       bin_iv  total_iv breaks is_special_values\n        <num>     <num> <char>            <lgcl>\n1: 0.09296873 0.2209836      2             FALSE\n2: 0.12801486 0.2209836    Inf             FALSE\n\n$Age\n   variable       bin count count_distr   neg   pos   posprob        woe\n     <char>    <char> <int>       <num> <int> <int>     <num>      <num>\n1:      Age [-Inf,35)  3678  0.36787357  3388   290 0.0788472 -1.0956541\n2:      Age   [35,42)  3106  0.31066213  2641   465 0.1497102 -0.3744154\n3:      Age   [42,45)   874  0.08741748   635   239 0.2734554  0.3852986\n4:      Age [45, Inf)  2340  0.23404681  1296  1044 0.4461538  1.1462370\n       bin_iv  total_iv breaks is_special_values\n        <num>     <num> <char>            <lgcl>\n1: 0.31043361 0.7642339     35             FALSE\n2: 0.03879657 0.7642339     42             FALSE\n3: 0.01444791 0.7642339     45             FALSE\n4: 0.40055578 0.7642339    Inf             FALSE\n\n$IsActiveMember\n         variable      bin count count_distr   neg   pos   posprob        woe\n           <char>   <char> <int>       <num> <int> <int>     <num>      <num>\n1: IsActiveMember [-Inf,1)  4850    0.485097  3547  1303 0.2686598  0.3610272\n2: IsActiveMember [1, Inf)  5148    0.514903  4413   735 0.1427739 -0.4299794\n       bin_iv total_iv breaks is_special_values\n        <num>    <num> <char>            <lgcl>\n1: 0.06994876 0.153257      1             FALSE\n2: 0.08330821 0.153257    Inf             FALSE\n\n$Geography\n    variable              bin count count_distr   neg   pos   posprob\n      <char>           <char> <int>       <num> <int> <int>     <num>\n1: Geography France%,%missing  5012   0.5013003  4202   810 0.1616121\n2: Geography            Spain  2476   0.2476495  2063   413 0.1668013\n3: Geography          Germany  2510   0.2510502  1695   815 0.3247012\n          woe     bin_iv  total_iv           breaks is_special_values\n        <num>      <num>     <num>           <char>            <lgcl>\n1: -0.2838216 0.03702196 0.1687521 France%,%missing             FALSE\n2: -0.2460089 0.01390472 0.1687521            Spain             FALSE\n3:  0.6302102 0.11782546 0.1687521          Germany             FALSE\n\n$Gender\n   variable    bin count count_distr   neg   pos   posprob        woe\n     <char> <char> <int>       <num> <int> <int>     <num>      <num>\n1:   Gender   Male  5456   0.5457091  4557   899 0.1647727 -0.2606767\n2:   Gender Female  4542   0.4542909  3403  1139 0.2507706  0.2679534\n       bin_iv   total_iv breaks is_special_values\n        <num>      <num> <char>            <lgcl>\n1: 0.03424476 0.06944544   Male             FALSE\n2: 0.03520068 0.06944544 Female             FALSE\n\n$EstimatedSalary\n          variable             bin count count_distr   neg   pos   posprob\n            <char>          <char> <int>       <num> <int> <int>     <num>\n1: EstimatedSalary    [-Inf,25000)  1217  0.12172434   975   242 0.1988496\n2: EstimatedSalary   [25000,35000)   501  0.05011002   388   113 0.2255489\n3: EstimatedSalary   [35000,60000)  1243  0.12432486  1013   230 0.1850362\n4: EstimatedSalary   [60000,75000)   759  0.07591518   589   170 0.2239789\n5: EstimatedSalary   [75000,85000)   523  0.05231046   436    87 0.1663480\n6: EstimatedSalary  [85000,155000)  3519  0.35197039  2807   712 0.2023302\n7: EstimatedSalary [155000,185000)  1499  0.14992999  1166   333 0.2221481\n8: EstimatedSalary   [185000, Inf)   737  0.07371474   586   151 0.2048847\n            woe       bin_iv    total_iv breaks is_special_values\n          <num>        <num>       <num> <char>            <lgcl>\n1: -0.031039680 1.161992e-04 0.008733362  25000             FALSE\n2:  0.128842544 8.636055e-04 0.008733362  35000             FALSE\n3: -0.120132130 1.730571e-03 0.008733362  60000             FALSE\n4:  0.119832318 1.128837e-03 0.008733362  75000             FALSE\n5: -0.249274060 3.012467e-03 0.008733362  85000             FALSE\n6: -0.009333600 3.057754e-05 0.008733362 155000             FALSE\n7:  0.109268188 1.848061e-03 0.008733362 185000             FALSE\n8:  0.006420112 3.044140e-06 0.008733362    Inf             FALSE\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_bineed <- woebin_ply(df,bins = bins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✔ Woe transformating on 9998 rows and 6 columns in 00:00:01\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(df_bineed, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   RowNumber CustomerId  Surname CreditScore Tenure   Balance HasCrCard Exited\n       <int>      <int>   <char>       <int>  <int>     <num>     <int>  <int>\n1:         1   15634602 Hargrave         619      2      0.00         1      1\n2:         2   15647311     Hill         608      1  83807.86         0      0\n3:         3   15619304     Onio         502      8 159660.80         1      1\n4:         4   15701354     Boni         699      1      0.00         0      0\n5:         6   15574012      Chu         645      8 113755.78         1      1\n   ModVal prbm_NumOfProducts  prbm_Age prbm_IsActiveMember prbm_Geography\n    <num>              <num>     <num>               <num>          <num>\n1:      1          0.2776061 0.1208350           0.2732064      0.1667147\n2:      0          0.2776061 0.1208350           0.2732064      0.1624077\n3:      0          0.8744770 0.1208350           0.1451298      0.1667147\n4:      0          0.0800000 0.1208350           0.1451298      0.1667147\n5:      0          0.0800000 0.3450704           0.1451298      0.1624077\n   prbm_Balance prbm_Gender prbm_CreditScore prbm_EstimatedSalary         Y\n          <num>       <num>            <num>                <num>     <num>\n1:    0.1368209   0.2507042        0.2057307            0.1990913 -2.291211\n2:    0.2466209   0.2507042        0.2057307            0.1990913 -2.313884\n3:    0.2466209   0.2507042        0.2057307            0.1990913  2.340290\n4:    0.1368209   0.2507042        0.2057307            0.1990913 -2.518418\n5:    0.2466209   0.1714436        0.2057307            0.1990913 -1.773778\n           RL NumOfProducts_woe    Age_woe IsActiveMember_woe Geography_woe\n        <num>             <num>      <num>              <num>         <num>\n1: 0.90814650         0.4043315  0.3852986         -0.4299794    -0.2838216\n2: 0.91002041         0.4043315 -0.3744154         -0.4299794    -0.2460089\n3: 0.08784071        -0.5567511  0.3852986          0.3610272    -0.2838216\n4: 0.92542293        -0.5567511 -0.3744154          0.3610272    -0.2838216\n5: 0.85492687        -0.5567511  0.3852986          0.3610272    -0.2460089\n   Gender_woe EstimatedSalary_woe\n        <num>               <num>\n1:  0.2679534          -0.0093336\n2:  0.2679534          -0.0093336\n3:  0.2679534          -0.0093336\n4:  0.2679534          -0.0093336\n5: -0.2606767          -0.0093336\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generación de muestras para el performance del modelo\nmod <- df_bineed[ModVal == 0 & Exited %in% c(0,1)]\nval <- df_bineed[ModVal ==1]\n# Regresión logistica\nformula <- \"Exited ~\n  NumOfProducts_woe +\n  Age_woe +\n  IsActiveMember_woe +\n  Geography_woe + \n  Gender_woe +\n  EstimatedSalary_woe\n\"\nmodelo <- glm(formula = as.formula(formula), family = binomial(\"logit\"), data = mod)\n\nsummary(modelo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = as.formula(formula), family = binomial(\"logit\"), \n    data = mod)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         -1.32127    0.03436 -38.457  < 2e-16 ***\nNumOfProducts_woe    0.88080    0.07163  12.297  < 2e-16 ***\nAge_woe              1.03291    0.03853  26.806  < 2e-16 ***\nIsActiveMember_woe   1.23838    0.08731  14.184  < 2e-16 ***\nGeography_woe        0.99349    0.07884  12.602  < 2e-16 ***\nGender_woe           0.86631    0.12656   6.845 7.65e-12 ***\nEstimatedSalary_woe  0.77650    0.35711   2.174   0.0297 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7149.2  on 6997  degrees of freedom\nResidual deviance: 5690.5  on 6991  degrees of freedom\nAIC: 5704.5\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnom_vars <- all.vars(terms(modelo))[-1]\nres <- cor(setDT(mod)[, ..nom_vars])\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    NumOfProducts_woe      Age_woe IsActiveMember_woe\nNumOfProducts_woe        1.0000000000  0.077205537         0.02528692\nAge_woe                  0.0772055374  1.000000000        -0.03600072\nIsActiveMember_woe       0.0252869155 -0.036000718         1.00000000\nGeography_woe            0.0362993628  0.062453734         0.02570862\nGender_woe              -0.0051035218  0.041384541         0.02861081\nEstimatedSalary_woe     -0.0002743988 -0.000688623         0.02210737\n                    Geography_woe   Gender_woe EstimatedSalary_woe\nNumOfProducts_woe      0.03629936 -0.005103522       -0.0002743988\nAge_woe                0.06245373  0.041384541       -0.0006886230\nIsActiveMember_woe     0.02570862  0.028610806        0.0221073663\nGeography_woe          1.00000000  0.018463506        0.0163394609\nGender_woe             0.01846351  1.000000000       -0.0015705987\nEstimatedSalary_woe    0.01633946 -0.001570599        1.0000000000\n```\n\n\n:::\n\n```{.r .cell-code}\neigen(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\neigen() decomposition\n$values\n[1] 1.1293676 1.0415320 1.0050447 0.9873191 0.9563795 0.8803571\n\n$vectors\n            [,1]        [,2]        [,3]       [,4]        [,5]        [,6]\n[1,] -0.51994721 -0.08399426  0.35618599 -0.4434461  0.43423271  0.45883434\n[2,] -0.61446110 -0.35014917 -0.06401573  0.1887344  0.14251679 -0.66317673\n[3,] -0.10513934  0.75866654 -0.02132252 -0.4742214  0.01207762 -0.43345625\n[4,] -0.51162371  0.15684900  0.08886514  0.1162957 -0.79514618  0.24486818\n[5,] -0.27141610  0.23627091 -0.81765353  0.1930863  0.25525188  0.31546188\n[6,] -0.07491766  0.46296874  0.43832016  0.7014570  0.30589882  0.04802835\n```\n\n\n:::\n\n```{.r .cell-code}\nsqrt( head(eigen(res)$values,1) / tail(eigen(res)$values,1)) # calculo IC > 5 indicios multicolinealidad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.13263\n```\n\n\n:::\n\n```{.r .cell-code}\ndf_bineed[, Y:= modelo$coefficients[1] + Reduce(`+`, Map(function(var, coef) get(var) * coef, names(modelo$coefficients[-1]), modelo$coefficients[-1]))]\ndf_bineed[, RL := (1 / (1 + exp(Y)))]\n#quantile(df_bineed$RL, probs = seq(0 , 1, by = 0.01))\n\nmod <- df_bineed[ModVal == 0 & Exited %in%  c(0,1)]\nval <- df_bineed[ModVal == 1]\n\n# Estimación  Probabilidades\nres_mod <- data.table(Var = mod$Exited, RL = mod$RL)\n\nres_val <- data.table(Var = val$Exited, RL = val$RL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráficas ROC\n#library(pROC)\nobjroc1 <- roc(res_mod$Var, res_mod$RL, auc=T, ci=T)\nplot(objroc1, col=\"blue\", xlab=\"1 - Especificidad\", ylab=\"Sensibilidad\", main=\"Comparación curvas ROC\", legacy.axes = TRUE)\nobjroc2 <- roc(res_val$Var, res_val$RL, auc=T, ci=T)\nplot(objroc2, col=\"red\", add=TRUE)\nlegend(\"bottomright\", legend=c(paste(\"Modelamiento\",round(objroc1$auc, 3)), paste(\"Validación\", round(objroc2$auc, 3))), col=c(\"blue\", \"red\"), lwd=0.5, title = \"AUC-ROC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nCon la librería `scorecard` se ha alcanzado un AUC-ROC de validación de 0.815\n\n## Ensamble\n\nCreamos y damos formato necesario para utilizar `h2o`, nota en esta ocasión trabajaremos con las variables binneadas de forma personalizada\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ejecución del Ensamble\n\nlibrary(h2o)\nh2o.init(ip = \"localhost\", nthreads = 2, max_mem_size = \"5G\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         28 minutes 41 seconds \n    H2O cluster timezone:       America/Guayaquil \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    8 months and 13 days \n    H2O cluster name:           H2O_started_from_R_joelb_nrn194 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   4.91 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  2 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.3.3 (2024-02-29 ucrt) \n```\n\n\n:::\n\n```{.r .cell-code}\n# Establecemos los datos en el formato adecuado\nvars <- c(\"Exited\", \"prbm_NumOfProducts\", \"prbm_Age\", \"prbm_IsActiveMember\", \"prbm_Geography\", \"prbm_Gender\", \"prbm_EstimatedSalary\")\n\nmod_em <- as.h2o(x = setDT(mod)[, vars, with = FALSE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\n# Identificamos predictores y respuesta\ny_em <- \"Exited\"; x_em <- setdiff(names(mod_em), y_em)\n\n# Para la clasificación binaria, la respuesta debe ser un factor \nmod_em[,y_em] <- as.factor(mod_em[,y_em])\n\n# Numero de CV folds \nnfolds <- 5\n\n# Generaremos el ensamble con 3 modelos (RF + GLM + GBM)\n```\n:::\n\n\n\n## Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train & Cross- validate a RF\nmy_rf <- h2o.randomForest(x = x_em,\n                          y = y_em,\n                          model_id = \"RF\",\n                          training_frame = mod_em,\n                          ntrees = 300,\n                          min_rows = 50,\n                          mtries = 5,\n                          nfolds = nfolds,\n                          fold_assignment = \"Stratified\",\n                          keep_cross_validation_predictions = TRUE,\n                          seed = 95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nh2o.confusionMatrix(my_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.239020037913721:\n          0    1    Error        Rate\n0      4556  989 0.178359   =989/5545\n1       425 1028 0.292498   =425/1453\nTotals 4981 2017 0.202058  =1414/6998\n```\n\n\n:::\n:::\n\n\n\n## Gradient Boosting Machine\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train & Cross-validate a GBM\nmy_gbm <- h2o.gbm(x = x_em,\n                  y = y_em,\n                  model_id = \"GBM\",\n                  training_frame = mod_em,\n                  distribution = \"bernoulli\",\n                  ntrees = 300,\n                  max_depth = 5,\n                  min_rows = 50,\n                  learn_rate = 0.02,\n                  nfolds = nfolds,\n                  fold_assignment = \"Stratified\",\n                  keep_cross_validation_predictions = TRUE,\n                  seed = 95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nh2o.confusionMatrix(my_gbm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.324439576278591:\n          0    1    Error        Rate\n0      5050  495 0.089270   =495/5545\n1       587  866 0.403992   =587/1453\nTotals 5637 1361 0.154616  =1082/6998\n```\n\n\n:::\n:::\n\n\n\n\n## Regresión Logística\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train & Cross-validate a GLM\nmy_glm <- h2o.glm(x = x_em,\n                  y = y_em,\n                  model_id = \"GLM\",\n                  training_frame = mod_em,\n                  alpha = 0.1, # penaliza inclusión excesiva de variables\n                  remove_collinear_columns = TRUE,\n                  nfolds = nfolds,\n                  fold_assignment = \"Stratified\",\n                  keep_cross_validation_predictions = TRUE,\n                  seed = 95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nh2o.confusionMatrix(my_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.297621966238341:\n          0    1    Error        Rate\n0      4920  625 0.112714   =625/5545\n1       569  884 0.391604   =569/1453\nTotals 5489 1509 0.170620  =1194/6998\n```\n\n\n:::\n:::\n\n\n\n\n## Ensamble RF + GBM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train ensamble\n\ne1m <- h2o.stackedEnsemble(x = x_em,\n                           y = y_em,\n                           training_frame = mod_em,\n                           model_id = \"Ensamble_1m\",\n                           metalearner_algorithm = \"deeplearning\",\n                           base_models = list(my_rf, my_gbm))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n:::\n\n\n\n## Ensamble RF + RL\n\n\n::: {.cell}\n\n```{.r .cell-code}\ne2m <- h2o.stackedEnsemble(x = x_em,\n                           y = y_em,\n                           training_frame = mod_em,\n                           model_id = \"Ensamble_2m\",\n                           metalearner_algorithm = \"deeplearning\",\n                           base_models = list(my_rf, my_glm))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n:::\n\n\n\n\nEnsamble RF + RL + GBM \n\n\n::: {.cell}\n\n```{.r .cell-code}\ne3m <- h2o.stackedEnsemble(x = x_em,\n                           y = y_em,\n                           training_frame = mod_em,\n                           model_id = \"Ensamble3m\",\n                           metalearner_algorithm = \"deeplearning\",\n                           base_models = list(my_rf, my_gbm, my_glm))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n:::\n\n\n\n## Predicciones \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Realizamos los predicciones sobre la muestra de modelamiento / validación\nmod_em <- as.h2o(x = setDT(mod)[, vars, with = FALSE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_em <- as.h2o(x = setDT(val)[, vars, with = FALSE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nmod_em[,y_em] <- as.factor(mod_em[, y_em])\nval_em[,y_em] <- as.factor(val_em[, y_em])\n\nres_f <- function(valida, resul){\n  res <- data.frame(Exited = valida$Exited,\n                    Exited_p = as.data.frame(resul)[,3],0)\n  return(res)\n} \n\nroc_graf <- function(res_mod, res_val, name=\"\"){\nobjroc1 <- roc(res_mod$Exited, res_mod$Exited_p, auc=T, ci=T)\nplot(objroc1, col=\"blue\", xlab=\"1 - Especificidad\", ylab=\"Sensibilidad\", main=paste(\"Comparación curvas ROC\",name), legacy.axes = TRUE)\nobjroc2 <- roc(res_val$Exited, res_val$Exited_p, auc=T, ci=T)\nplot(objroc2, col=\"red\", add=TRUE)\nlegend(\"bottomright\", legend=c(paste(\"Modelamiento\",round(objroc1$auc, 3)), paste(\"Validación\", round(objroc2$auc, 3))), col=c(\"blue\", \"red\"), lwd=0.5, title = \"AUC-ROC\")\n}\n```\n:::\n\n\n\n## Curva ROC RF\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Random Forest\nmod_rf <- setDT(res_f(mod, h2o.predict(my_rf, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_rf <- setDT(res_f(val, h2o.predict(my_rf, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_rf,val_rf, \"RF\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n## Curva ROC RL\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regresión Logística\nmod_glm <- setDT(res_f(mod, h2o.predict(my_glm, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_glm <- setDT(res_f(val, h2o.predict(my_glm, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_glm,val_glm, \"Regresión Logística\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n## Curva ROC GBM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gradient Boosting \nmod_gbm <- setDT(res_f(mod, h2o.predict(my_gbm, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_gbm <- setDT(res_f(val, h2o.predict(my_gbm, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_gbm,val_gbm, \"Gradient Boosting\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n## Curva ROC RF + GBM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensamble RF + GBM\nmod_e1m <- setDT(res_f(mod, h2o.predict(e1m, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_e1m <- setDT(res_f(val, h2o.predict(e1m, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_e1m,val_e1m, \"Ensamble RF + GBM\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n## Curva ROC RF + RL\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensamble GLM +RF\nmod_e2m <- setDT(res_f(mod, h2o.predict(e2m, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_e2m <- setDT(res_f(val, h2o.predict(e2m, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_e2m,val_e2m, \"Ensamble RF + GLM(RL)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n## Curva ROC RL + RF + GBM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensamble GLM + RF + GBM\nmod_e3m <- setDT(res_f(mod, h2o.predict(e3m, newdata = mod_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nval_e3m <- setDT(res_f(val, h2o.predict(e3m, newdata = val_em)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nroc_graf(mod_e3m,val_e3m, \"Ensamble RF + GBM + GLM(RL)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n# Conclusiones \n\n* Notemos que en la mayoria de casos se ha alcanzado AUC-ROC $\\geq 0.80$ sin embargo el mejor modelo es el Ensamble de Random Forest + Gradient Boosting Machine + GLM( Regresión Logística)  con una AUC-ROC validación de $0.85$. Sin embargo el modelo también se ve sometido a requerimientos y recursos propios del negocio por lo que puede quedarse fuera y se opte por un modelo menos costoso en cuestión de tiempo y recursos.\n\n\n# Recomendaciones\n\n* En esta ocasión no hemos recurrido a una automatización completa del proceso de creación del modelo por lo que se podría explorar la creación de ensambles partiendo de las variables binneadas por optimal binning. \n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}