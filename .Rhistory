knitr::opts_chunk$set(echo = TRUE,error = F, message = F, warning = F,comment = "") #c. habitual
xaringanExtra::use_clipboard()
library(prettydoc) #Paquete de tema favorito
library(reticulate) #Paquete de python en R
use_python("C:\\Users\\JXBS\\AppData\\Local\\Programs\\Python\\Python312\\python.exe")
library(kableExtra)
library(htmltools)
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from scipy import stats
keane=pd.read_csv("keane.csv")
quit
DT::datatable(head(py$keane),
rownames = F,
extensions = 'FixedColumns',
options = list(
info=F,
pageLength=5,
autoWidth=T,
scrollX=T,
paging=F,
searching=F,
initComplete = DT::JS("function(settings, json) {$(this.api().table().header()).css({'font-size' : '12px','color':'#fff','background-color':'#3C3B3A'});}")
)) %>%
DT::formatStyle(names(py$keane), backgroundColor="#949797", color = "#F6FBFB")
reticulate::repl_python()
keane["choice"]=np.where(keane["choice"]==1,"estudiante",
np.where(keane["choice"]==2,"hogar",
np.where(keane["choice"]==3,"cualificado",
np.where(keane["choice"]==4,"no-cualificado","servicio"))))
sb.scatterplot(data=keane,x="year",y="wage",hue="black")
sb.scatterplot(data=keane[keane["employ"]==1],x="year", y="wage",hue="choice")
keane["educCode"]=np.where(keane["educ"]<=9,1,np.where(keane["educ"]<=12,2,3))
sb.scatterplot(data=keane[keane["employ"]==1],x="year",y="wage",hue="educCode")
sb.scatterplot(data=keane[keane["employ"]==1],x="year", y="wage",hue="choice")
plt.show()
sb.scatterplot(data=keane[keane["employ"]==1],x="year",y="wage",hue="educCode")
plt.show
sb.scatterplot(data=keane[keane["employ"]==1],x="year",y="wage",hue="educCode")
plt.show()
sb.scatterplot(data=keane,x="year",y="wage",hue="black")
sb.show()
quit
knitr::opts_chunk$set(echo = TRUE,error = F, message = F, warning = F,comment = "") #c. habitual
xaringanExtra::use_clipboard()
library(prettydoc) #Paquete de tema favorito
library(reticulate) #Paquete de python en R
use_python("C:\\Users\\JXBS\\AppData\\Local\\Programs\\Python\\Python312\\python.exe")
library(kableExtra)
library(htmltools)
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from scipy import stats
#para graficar dentro del jupyter notebook
%matplotlib inline
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from scipy import stats
#para graficar dentro del jupyter notebook
%matplotlib inline
reticulate::repl_python()
keane=pd.read_csv("keane.csv")
quit
DT::datatable(head(py$keane),
rownames = F,
extensions = 'FixedColumns',
options = list(
info=F,
pageLength=5,
autoWidth=T,
scrollX=T,
paging=F,
searching=F,
initComplete = DT::JS("function(settings, json) {$(this.api().table().header()).css({'font-size' : '12px','color':'#fff','background-color':'#3C3B3A'});}")
)) %>%
DT::formatStyle(names(py$keane), backgroundColor="#949797", color = "#F6FBFB")
reticulate::repl_python()
keane["choice"]=np.where(keane["choice"]==1,"estudiante",
np.where(keane["choice"]==2,"hogar",
np.where(keane["choice"]==3,"cualificado",
np.where(keane["choice"]==4,"no-cualificado","servicio"))))
sb.scatterplot(data=keane,x="year",y="wage",hue="black")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
%matplotlib inline
reticulate::repl_python()
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
%matplotlib inline
reticulate::repl_python()
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
from IPython import get_ipython
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
from IPython import get_ipython
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
from IPython import get_ipython
get_ipython.run_line_magic('matplotlib', 'inline')
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
from IPython import get_ipython
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
'exec(%matplotlib inline)'
sb.scatterplot(data=keane[keane["employ"]==1],x="year", y="wage",hue="choice")
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
exec(%matplotlib inline)
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sb
#para graficar dentro del jupyter notebook
from IPython import get_ipython
ipy = get_ipython()
if ipy is not None:
ipy.run_line_magic('matplotlib', 'inline')
sb.scatterplot(data=keane,x="year",y="wage",hue="black")
sb.scatterplot(data=keane,x="year",y="wage",hue="black")
sb.scatterplot(data=keane[keane["employ"]==1],x="year", y="wage",hue="choice")
sb.scatterplot(data=keane[keane["employ"]==1],x="year",y="wage",hue="educCode")
plt.show()
sb.scatterplot(data=keane[keane["employ"]==1],x="year",y="wage",hue="educCode")
exit
reticulate::repl_python()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb
df=pd.read_csv("creditcard.csv.zip")
df.shape
df.info()
df.isnull()
df.isnull().any()
df["Class"].value_counts()
df['Class'].value_counts(normalize=True)
from sklearn.model_selection import train_test_split
X=df.drop(labels='Class',axis=1)
y=df.loc[:,'Class']
X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1, stratify=y)
X_train.shape
X_test.shape
X_train.dtypes()
X_train.dtypes
X_train.describe()
X_train['Time'].describe()
X_train.loc[:,'Time']=X_train.Time/3600
X_test.loc[:,'Time']=X_test.Time/3600
plt.figure(figsize=(12,4))
sb.displot(X_train['Time'],bins=40,kde=False)
plt.xlim([0,40])
plt.xticks(np.arrange(0,48,6))
plt.xlabel('Tiempo despues de la primera transacci贸n (h)')
plt.ylabel('Conteo')
plt.title('Tiempo de transacciones')
plt.show()
X_train['Amount'].describe()
View(y_train)
View(y_train)
plt.figure(figsize=(10,7))
sb.boxplot(X_train['Amount'])
plt.show()
plt.figure(figsize=(12,4))
sb.displot(X_train['Amount'],bins=300,kde=False)
plt.ylabel('Conteo')
plt.title('Montos de Transacci贸n')
plt.show()
sb.displot(X_train['Amount'],bins=100,kde=False)
plt.figure(figsize=(12,4))
sb.displot(X_train['Amount'],bins=100,kde=False)
plt.ylabel('Conteo')
plt.title('Montos de Transacci贸n')
plt.show()
plt.figure(figsize=(12,4))
sb.displot(X_train['Amount'],bins=50,kde=False)
plt.ylabel('Conteo')
plt.title('Montos de Transacci贸n')
plt.show()
plt.figure(figsize=(12,4))
sb.boxplot(x=X_train['Amount'])
plt.show()
plt.figure(figsize=(12,4))
sb.boxplot(x=X_train["Amount"])
plt.show()
X_train['Amount'].skew()
X_train.head(5)
"D:\Joel\Blog\jb_blog\certificados\25-05-2023_Curso_power-BI\Power_BI.pdf"
"D:/Joel/Blog/jb_blog/certificados/25-05-2023_Curso_power-BI/Power_BI.pdf"
install.packages("quarto")
install.packages("quarto")
install.packages("class")
library(class)
library(caret)
library(ggplot2)
library(class)
library(caret)
library(ggplot2)
data <- read.csv("Iris.csv")
X <- data[,-c(1,5)]
y <- data$Species
set.seed(42)
trainIndex <- createDataPartition(y, p = .7, list = FALSE)
X_train <- X[trainIndex,]
X_test <- X[-trainIndex,]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]
preProcValues <- preProcess(X_train, method = c("center", "scale"))
X_train <- predict(preProcValues, X_train)
X_test <- predict(preProcValues, X_test)
knn_model <- class::knn(train = X_train, test = X_test, cl = y_train, k = 3)
View(X_train)
View(X_test)
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = 3)
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = 3)
is_na(X_train)
is.na(X_train)
is.na(X_test)
help("knn")
class(y_train)
knn_model <- knn(train = X_train, test = X_test, cl = as.factor(y_train), k = 3)
typeof(y_train)
typeof(as.factor(y_train))
knn_model <- knn3(train = X_train, test = X_test, cl = y_train, k = 3)
help("knn3")
knn_model <- knn3(x = X_train, y = y_train, k = 3)
knn_model <- knn3(x = X_train, y = as.factor(y_train), k = 3)
confusion <- confusionMatrix(knn_model, y_test)
knn_model$k
knn_model$learn
knn_model <- knn3Train(X_train, y_train, cl = y_test, k = 3)
knn_model <- knn3Train(X_train, X_test, cl = y_train, k = 3)
knn_model <- knn3Train(train = X_train, test = X_test, cl = y_train, k = 3)
knn_model <- knn3Train(train = X_train, test = X_test, cl = y_train, k = 3, l = 0, prob = TRUE, use.all = TRUE)
knn3Train
reticulate::repl_python()
import pandas as pd
pd.options.display.max_columns=None
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sb
data = pd.read_csv("Iris.csv")
X = data.drop(['Id', 'Species'], axis=1)
y = data['Species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
print('Confusion Matrix:\n', confusion_matrix(y_test, y_pred))
print('Classifcation Report:\n', classification_repor(y_test, y_pred))
print('Confusion Matrix:\n', confusion_matrix(y_test, y_pred))
print('Classifcation Report:\n', classification_repor(y_test, y_pred))
library(class)
library(caret)
library(ggplot2)
data <- read.csv("Iris.csv")
X <- data[,-c(1,5)]
y <- data$Species
set.seed(42)
trainIndex <- createDataPartition(y, p = .7, list = FALSE)
X_train <- X[trainIndex,]
X_test <- X[-trainIndex,]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]
preProcValues <- preProcess(X_train, method = c("center", "scale"))
X_train <- predict(preProcValues, X_train)
X_test <- predict(preProcValues, X_test)
#| eval: false
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = 3)
reticulate::repl_python()
data = pd.read_csv("Iris.csv")
quit
data <- read.csv("Iris.csv")
head(data)
data <- data[,-1]
any(is.na(data))
head(data)
X <- data[,-5]
head(X)
y <- data$Species
set.seed(42)
trainIndex <- createDataPartition(y, p = .7, list = FALSE)
X_train <- X[trainIndex,]
X_test <- X[-trainIndex,]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]
preProcValues <- preProcess(X_train, method = c("center", "scale"))
X_train <- predict(preProcValues, X_train)
X_test <- predict(preProcValues, X_test)
#| eval: false
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = 3)
install.packages("GGally")
knn_model
y_pred
y_test
reticulate::repl_python()
import pandas as pd
df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
print(df.head())
print(df.info())
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')
df = df.fillna(df.mean())
df = pd.get_dummies(df, drop_first=True)
X = df.drop('Churn_Yes', axis = 1)
y = df['Churn_Yes']
import pandas as pd
df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
print(df.head())
print(df.info())
df['TotalCharges']
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')
df['TotalCharges'].dtype
df = df.fillna(df.mean())
df['TotalCharges'].isnull()
df['TotalCharges'].isnull().count()
df['TotalCharges'].isnull().sum()
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].mean())
df = pd.get_dummies(df, drop_first=True)
X = df.drop('Churn_Yes', axis = 1)
y = df['Churn_Yes']
import pandas as pd
df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
print(df.head())
print(df.info())
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].mean())
df = pd.get_dummies(df, drop_first=True)
X = df.drop('Churn_Yes', axis = 1)
y = df['Churn_Yes']
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
lr_model = LogisticRegression(max_iter = 1000)
lr_model.fit(X_train, y_train)
reticulate::repl_python()
import pandas as pd
data = pd.read_csv("house_prices.csv")
print(data.head())
print(data.info())
from sklearn.model_selection import train_test_split
X = data.drop('SalePrice', axis =1)
y = data['SalePrice']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 95)
print(y_train.value_counts(normalize = True))
from sklearn.model_selection import train_test_split
X = data.drop('SalePrice', axis =1)
data.head
data.head()
