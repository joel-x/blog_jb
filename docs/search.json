[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joel Burbano",
    "section": "",
    "text": "Ingeniero Matem√°tico\nAnalista de Datos\nCient√≠fico de Datos"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca de mi",
    "section": "",
    "text": "üëã ¬°Hola! Soy Joel, graduado de Ingeniero Matem√°tico en la Facultad de Ciencias de la Escuela Polit√©cnica Nacional.\nüéì Durante mi etapa universitaria he adquirido las bases para gestionar modelos de riesgo, modelos econom√©tricos, modelos estad√≠sticos, modelos de programaci√≥n entera. As√≠ tambi√©n, he adquirido las bases de matem√°tica actuarial, estad√≠stica matem√°tica, investigaci√≥n operativa. Adem√°s, me he capacitado en el manejo de lenguajes de programaci√≥n tales como: C++, Matlab, R, Python, y tambi√©n manejo de paquetes estad√≠sticos Statgraphics y Gretl.\nüìù El desarrollo de mi trabajo de titulaci√≥n se enfoca en desarrollar un modelo de consumo a partir de la Hip√≥tesis de Renta Permanente de Friedman (Novel Economia,1976) y El Ciclo de Vida de Modigliani.\nüéØMi objetivo es seguir desarrollando mis habilidades en el √°rea estad√≠stica, econom√©trica, actuarial y ciencia de datos, por lo que me encuentro altamente interesado en trabajar en las mencionadas √°reas."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Ordenar por\n       Por defecto\n         \n          T√≠tulo\n        \n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - M√°s reciente\n        \n         \n          Autor/a\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nAccidentes automovilisticos Conjunto de datos EDA\n\n\n\nPython\n\n\n\nEn este apartado vamos a analizar datos de accidentes automovilisticos\n\n\n\nJoel burbano\n\n\n13 ene 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGaussian Mixture Models\n\n\n\nPython\n\n\nAprendizaje No Supervisado\n\n\nClusters\n\n\n\n\n\n\n\nJoel Burbano\n\n\n20 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAnalisis de Componentes Principales\n\n\n\nPython\n\n\nPCA\n\n\nReducci√≥n de dimensiones\n\n\nAprendizaje No Supervisado\n\n\n\n\n\n\n\nJoel Burbano\n\n\n20 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegresi√≥n Lineal Simple\n\n\n\nPython\n\n\nAprendizaje Supervisado\n\n\n\n\n\n\n\nJoel Burbano\n\n\n19 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNaive Bayes Clasificaci√≥n\n\n\n\nAprendizaje supervisado\n\n\nPython\n\n\nNaive Bayes\n\n\n\n\n\n\n\nJoel Burbano\n\n\n19 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDetecci√≥n de fraude con tarjetas de Cr√©dito\n\n\n\nPython\n\n\n\nEn el presente proyecto se pretende analizar un conjunto de datos de transacciones crediticias.\n\n\n\nJoel Burbano\n\n\n17 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHiperparametros y Modelos de Validaci√≥n\n\n\n\nPython\n\n\nMachine Learning\n\n\n\n\n\n\n\nJoel Burbano\n\n\n17 dic 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTratando los datos Keane\n\n\n\nEconometr√≠a\n\n\nPython\n\n\n\nEn este post se realizara un analisis de los datos keane\n\n\n\nJoel Burbano\n\n\n7 dic 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "proyects.html",
    "href": "proyects.html",
    "title": "Proyectos",
    "section": "",
    "text": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)\n\n\n\nRenta permanente\n\n\nModelo de Ciclo de vida\n\n\nEcuaci√≥n de Euler\n\n\nCausalidad\n\n\nModelos de Consumo\n\n\n\nEl estudio del modelo te√≥rico del consumo es un tema de relevancia tanto a nivel de individuo como nivel de hogares. Es as√≠ que, en este trabajo se realiza una nueva‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/2020-12-01-r-rmarkdown/index.html",
    "href": "posts/2020-12-01-r-rmarkdown/index.html",
    "title": "Hello R Markdown",
    "section": "",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\n\nsummary(cars)\n##      speed           dist       \n##  Min.   : 4.0   Min.   :  2.00  \n##  1st Qu.:12.0   1st Qu.: 26.00  \n##  Median :15.0   Median : 36.00  \n##  Mean   :15.4   Mean   : 42.98  \n##  3rd Qu.:19.0   3rd Qu.: 56.00  \n##  Max.   :25.0   Max.   :120.00\nfit &lt;- lm(dist ~ speed, data = cars)\nfit\n## \n## Call:\n## lm(formula = dist ~ speed, data = cars)\n## \n## Coefficients:\n## (Intercept)        speed  \n##     -17.579        3.932\n\n\n\nIncluding Plots\nYou can also embed plots. See Figure @ref(fig:pie) for example:\n\npar(mar = c(0, 1, 0, 1))\npie(\n  c(280, 60, 20),\n  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),\n  col = c('#0292D8', '#F7EA39', '#C4B632'),\n  init.angle = -50, border = NA\n)\n\n\n\n\nA fancy pie chart.\n\n\n\n\n\nsummary(Orange)\n##  Tree       age         circumference  \n##  3:7   Min.   : 118.0   Min.   : 30.0  \n##  1:7   1st Qu.: 484.0   1st Qu.: 65.5  \n##  5:7   Median :1004.0   Median :115.0  \n##  2:7   Mean   : 922.1   Mean   :115.9  \n##  4:7   3rd Qu.:1372.0   3rd Qu.:161.5  \n##        Max.   :1582.0   Max.   :214.0"
  },
  {
    "objectID": "posts/2023-12-07-tratando-los-datos-keane/index.html",
    "href": "posts/2023-12-07-tratando-los-datos-keane/index.html",
    "title": "Tratando los datos Keane",
    "section": "",
    "text": "En este post abordaremos un poco los datos keane obtenidos de Gretl\nEmpezaremos por importar las librer√≠as necesarias\n\nimport pandas as pd\npd.options.display.max_columns=None\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt \nimport seaborn as sb\n\n\nA continuaci√≥n nos disponemos a visualizar los datos\n\nkeane=pd.read_csv(\"keane.csv\")\nkeane=pd.DataFrame(keane)\n\n\nkeane.head(5)\n\n\n\n\n\n\n\n\nid\nnumyrs\nyear\nchoice\nwage\neduc\nexpwc\nexpbc\nexpser\nmanuf\nblack\nlwage\nenroll\nemploy\nattrit\nexper\nexpersq\nstatus\n\n\n\n\n0\n1\n9\n81\n2.0\nNaN\n10\n0\n0\n0\n0.0\n1\nNaN\n0\n0\n0\n0\n0\n2.0\n\n\n1\n1\n9\n82\n2.0\nNaN\n10\n0\n0\n0\n0.0\n1\nNaN\n0\n0\n0\n0\n0\n2.0\n\n\n2\n1\n9\n83\n2.0\nNaN\n10\n0\n0\n0\n0.0\n1\nNaN\n0\n0\n0\n0\n0\n2.0\n\n\n3\n1\n9\n84\n1.0\nNaN\n10\n0\n0\n0\n0.0\n1\nNaN\n1\n0\n0\n0\n0\n1.0\n\n\n4\n1\n9\n85\n2.0\nNaN\n11\n0\n0\n0\n0.0\n1\nNaN\n0\n0\n0\n0\n0\n2.0\n\n\n\n\n\n\n\n\nCrearemos etiquetas para las observaciones de acuerdo a ‚Äúchoice‚Äù estudiante=1, hogar=2, cualificado=3, no-cualificado=4, servicio=5\n\nkeane[\"choice\"]=np.where(keane[\"choice\"]==1,\"estudiante\",\n         np.where(keane[\"choice\"]==2,\"hogar\",\n                  np.where(keane[\"choice\"]==3,\"cualificado\",\n                           np.where(keane[\"choice\"]==4,\"no-cualificado\",\"servicio\"))))\n\n\nProcedemos a gr√°ficar la evoluci√≥n de salarios separado por color de piel\n\nsb.scatterplot(data=keane,x=\"year\",y=\"wage\",hue=\"black\",style=\"black\",style_order=[1,0])\nplt.show()\nplt.clf()\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nEn esta gr√°fica evidenciamos que a lo largo de los a√±os aumenta la discriminaci√≥n.\nVisualicemos lo siguiente: seleccionando s√≥lo las personas que trabajan se realizara un gr√°fico de la evoluci√≥n de los salarios separados por la variable choice\n\nsb.scatterplot(data=keane[keane[\"employ\"]==1],x=\"year\", y=\"wage\",hue=\"choice\")\nplt.show()\nplt.clf()\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nSe observa que la terciarizaci√≥n de la econom√≠a ha aumentado las diferencias entre trabajadores cualificados y no cualificados, as√≠ como, entre servicio e industria.\nAhora procedamos al an√°lisis de la variable educ para ello primero la Codificaremos de acuerdo a educaci√≥n b√°sica=1, educaci√≥n media=2, y educaci√≥n superior=3.\n\nkeane[\"educCode\"]=np.where(keane[\"educ\"]&lt;=9,1,np.where(keane[\"educ\"]&lt;=12,2,3))\n\nSeleccionando solo las personas que trabajan tenemos lo siguiente:\n\nsb.scatterplot(data=keane[keane[\"employ\"]==1],x=\"year\",y=\"wage\",hue=\"educCode\")\nplt.show()\nplt.clf()\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/2023-07-30-prueba/index.html",
    "href": "posts/2023-07-30-prueba/index.html",
    "title": "Estad√≠stica Descriptiva",
    "section": "",
    "text": "La estad√≠stica descriptiva nos permite realizar el an√°lisis exploratorio de la informaci√≥n y el pre-procesamiento de la informaci√≥n antes de tener un modelo de machine learning.\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"cars.csv\")\ndf.head()\n\n   speed  dist\n0      4     2\n1      4    10\n2      7     4\n3      7    22\n4      8    16"
  },
  {
    "objectID": "posts/2023-12-06-power-bi/index.html",
    "href": "posts/2023-12-06-power-bi/index.html",
    "title": "Power BI",
    "section": "",
    "text": "Pruebas para publicar power bi"
  },
  {
    "objectID": "proyects/tesis/index.html",
    "href": "proyects/tesis/index.html",
    "title": "Tesis de Grado",
    "section": "",
    "text": "En este peque√±o blog, se hablara de las partes mas importantes desarrolladas en el trabajo de integraci√≥n curricular"
  },
  {
    "objectID": "posts/Deteccion_fraude/index.html",
    "href": "posts/Deteccion_fraude/index.html",
    "title": "Detecci√≥n de fraude con tarjetas de Cr√©dito",
    "section": "",
    "text": "En el presente proyecto se pretende analizar un conjunto de datos de transacciones crediticias recolectadas durante dos d√≠as en el mes de de Septiembre del 2013 por European cardholders\nEmpezaremos por importar las librerias necesarias para realizar el an√°lisis\n\nimport pandas as pd\npd.options.display.max_columns=None\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nProcedemos a leer los datos con pandas\n\n#df: base de datos de las transacciones\ndf=pd.read_csv(\"creditcard.csv.zip\")\n\nVerificamos que cantidad de datos tenemos\n\ndf.shape\n\n(284807, 31)\n\n\nTenemos que existen 31 columnas (variables) y 284807 filas (registros)\nAhora bien procedemos a revisar la calidad de este conjunto de datos\n\ndf.isnull().any()\n\nTime      False\nV1        False\nV2        False\nV3        False\nV4        False\nV5        False\nV6        False\nV7        False\nV8        False\nV9        False\nV10       False\nV11       False\nV12       False\nV13       False\nV14       False\nV15       False\nV16       False\nV17       False\nV18       False\nV19       False\nV20       False\nV21       False\nV22       False\nV23       False\nV24       False\nV25       False\nV26       False\nV27       False\nV28       False\nAmount    False\nClass     False\ndtype: bool\n\n\nObservamos que no hay variables con datos nulos.\nAhora bien echemos un vistazo a la variable Class la cual contiene la informaci√≥n sobre las transacciones fraudulentas\n\ndf[\"Class\"].value_counts()\n\nClass\n0    284315\n1       492\nName: count, dtype: int64\n\n\nNotamos que solamente 492 transacciones son fraudulentas\n\ndf['Class'].value_counts(normalize=True)\n\nClass\n0    0.998273\n1    0.001727\nName: proportion, dtype: float64\n\n\nes decir solo el \\(0.17\\%\\) de transacciones son fraudulentas\nAhora bien empecemos a intentar predecir\n\nfrom sklearn.model_selection import train_test_split\n\n\nX=df.drop(labels='Class',axis=1)\ny=df.loc[:,'Class']\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1, stratify=y)\n\nAhora bien, se realiza un an√°lisis exploratorio de los datos\n\nX_train['Time'].describe()\n\ncount    199364.000000\nmean      94675.212852\nstd       47536.519022\nmin           0.000000\n25%       54039.000000\n50%       84588.500000\n75%      139243.250000\nmax      172792.000000\nName: Time, dtype: float64\n\n\nRealicemos una conversi√≥n de la variable Time de segundos a horas para facilitar la interpretaci√≥n\n\nX_train.loc[:,'Time']=X_train.Time/3600\nX_test.loc[:,'Time']=X_test.Time/3600\n\n\nplt.figure(figsize=(12,4))\nsb.displot(X_train['Time'],bins=40,kde=False)\nplt.xlim([0,40])\nplt.xticks(np.arange(0,48,6))\nplt.xlabel('Tiempo despues de la primera transacci√≥n (h)')\nplt.ylabel('Conteo')\nplt.title('Tiempo de transacciones')\nplt.show()\n\n&lt;Figure size 1152x384 with 0 Axes&gt;\n\n\n\n\n\nNotamos que existen dos picos en la gr√°fica, el primero entre las 10 y 22 primeras horas y el segundo entre las 34 y 40 horas\nAnalicemos la variable Amount\n\nX_train['Amount'].describe()\n\ncount    199364.000000\nmean         88.659351\nstd         247.240287\nmin           0.000000\n25%           5.637500\n50%          22.000000\n75%          78.000000\nmax       25691.160000\nName: Amount, dtype: float64\n\n\nrealicemos una revisi√≥n gr√°fica\nprimero un histograma\n\nplt.figure(figsize=(12,4))\nsb.displot(X_train['Amount'],bins=50,kde=False)\nplt.ylabel('Conteo')\nplt.title('Montos de Transacci√≥n')\nplt.show()\n\n&lt;Figure size 1152x384 with 0 Axes&gt;\n\n\n\n\n\n\nplt.figure(figsize=(12,4))\nsb.boxplot(x=X_train[\"Amount\"])\nplt.show()\n\n\n\n\nObservemos que los datos se encuentran fuertemente sesgados a la derecha. Para asegurarnos calculamos la asimetr√≠a\n\nX_train['Amount'].skew()\n\n16.950540423177653\n\n\n\nX_train.head(5)\n\n\n\n\n\n\n\n\nTime\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nAmount\n\n\n\n\n105644\n19.340833\n1.135011\n-0.663898\n0.703924\n0.069871\n-0.488154\n1.312078\n-0.897198\n0.463148\n-0.478801\n0.396879\n0.268544\n0.752264\n0.264092\n-0.252977\n0.515272\n-3.211514\n1.648897\n-1.297012\n-2.246958\n-0.677938\n-0.331487\n-0.069644\n0.183987\n-0.618678\n0.089015\n0.521419\n0.086390\n0.004782\n1.00\n\n\n139790\n23.155278\n-1.786262\n1.118886\n1.347969\n-0.379954\n-1.240680\n0.467667\n0.081125\n0.964933\n0.042585\n-1.275754\n-1.871478\n0.375166\n0.692938\n-0.149358\n-0.396145\n0.802805\n-0.405073\n0.153925\n-0.241419\n-0.099266\n-0.047902\n-0.182530\n-0.162509\n-0.405178\n0.512595\n0.299398\n-0.042882\n-0.059130\n141.73\n\n\n158758\n31.034167\n-0.683414\n0.679341\n2.615556\n2.362138\n-0.012716\n0.603826\n0.574245\n-0.679978\n-0.811409\n2.035115\n-0.564418\n-1.407557\n-0.094656\n-0.859411\n1.749530\n0.099132\n-0.035668\n-0.053624\n1.656191\n0.372610\n-0.007167\n0.463597\n-0.243134\n0.084557\n-0.453177\n2.687676\n-1.084269\n-0.511626\n36.19\n\n\n130845\n22.067778\n1.183540\n-0.493000\n0.755202\n-0.963160\n-0.850295\n0.145905\n-0.794616\n0.302199\n1.656943\n-0.939787\n1.101727\n1.138109\n-0.592931\n0.156943\n0.903035\n-0.419096\n-0.207755\n0.403235\n0.614310\n-0.168134\n0.039588\n0.339340\n-0.053125\n-0.298049\n0.423994\n-0.652284\n0.102582\n0.017292\n1.00\n\n\n88908\n17.318056\n1.137583\n0.105478\n0.784402\n1.254973\n-0.600870\n-0.360836\n-0.161727\n0.076092\n0.280587\n0.015787\n1.084154\n1.016011\n-0.666982\n0.250706\n-0.835022\n-0.130522\n-0.216624\n-0.058071\n0.265563\n-0.178887\n-0.195692\n-0.443664\n0.046270\n0.516246\n0.447943\n-0.554949\n0.031821\n0.018177\n7.60"
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html",
    "href": "posts/Hyperparameters and Model Validation/index.html",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "",
    "text": "Machine Learning se trata de crear models desde los datos: por esta raz√≥n es necesario entender como se representa la data en una computadora. En nuestro caso particular con Scikit-Learn la manera de tratar la data es como una tabla.\n\n\nUna tabla basica es un arreglo bi-dimensional de datos, en donde cada fila representa un elemento individual del conjunto de datos, y cada columna representa cantidades realacionadas con cada uno de estos elementos.\nPor ejemplo la ya conocidada base iris\n\nimport seaborn as sb\niris=sb.load_dataset('iris')\niris.head()\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\nAqu√≠, cada fila de la data se refiere a la observaci√≥n de una flor, y el numero de filas es el total de flores observadas."
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#representaci√≥n-de-la-data-en-scikit-learn",
    "href": "posts/Hyperparameters and Model Validation/index.html#representaci√≥n-de-la-data-en-scikit-learn",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "",
    "text": "Machine Learning se trata de crear models desde los datos: por esta raz√≥n es necesario entender como se representa la data en una computadora. En nuestro caso particular con Scikit-Learn la manera de tratar la data es como una tabla.\n\n\nUna tabla basica es un arreglo bi-dimensional de datos, en donde cada fila representa un elemento individual del conjunto de datos, y cada columna representa cantidades realacionadas con cada uno de estos elementos.\nPor ejemplo la ya conocidada base iris\n\nimport seaborn as sb\niris=sb.load_dataset('iris')\niris.head()\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\nAqu√≠, cada fila de la data se refiere a la observaci√≥n de una flor, y el numero de filas es el total de flores observadas."
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#matriz-de-caracteristicas-features-matrix",
    "href": "posts/Hyperparameters and Model Validation/index.html#matriz-de-caracteristicas-features-matrix",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "Matriz de caracteristicas (Features matrix)",
    "text": "Matriz de caracteristicas (Features matrix)\nEsta tabla contienene la informaci√≥n caracteeristica del conjunto de datos en nuestro ejemplo contiene informaci√≥n de flores. Matem√°ticamente estas caracteristicas pasan a representar las variables independientes de nuestro conjunto de datos generalmente denotado por \\(X\\)"
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#objetivo-target-array",
    "href": "posts/Hyperparameters and Model Validation/index.html#objetivo-target-array",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "Objetivo (Target Array)",
    "text": "Objetivo (Target Array)\nEs un arraglo que matem√°ticamente representa la variable dependiente generalmente notada por \\(y\\)\n\nimport matplotlib.pyplot as plt\n\n\n#plt.figure(figsize=(12,8))\nsb.set()\nsb.pairplot(iris,hue='species',size=1.5)\n\nC:\\Users\\JXBS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\axisgrid.py:2100: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\n\n\n\n\n\nPara usar los datos en Scikit-Learn, tenemos que extraer los matriz \\(X\\) y el objetivo \\(y\\)\n\nX_iris=iris.drop('species',axis=1)\nprint(X_iris.shape)\ny_iris=iris['species']\nprint(y_iris.shape)\n\n(150, 4)\n(150,)"
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#scikit-learns-api-estimador",
    "href": "posts/Hyperparameters and Model Validation/index.html#scikit-learns-api-estimador",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "Scikit-Learn‚Äôs API estimador",
    "text": "Scikit-Learn‚Äôs API estimador\nLa API de Scikit-Learn esta dise√±ada con los siguientes principios en mente\n\nCoherencia.- Todos los objetos comparten unaa interfaz com√∫n extraida de un conunto limitado de m√©todos, con documentaci√≥n consistente.\nInspecci√≥n Todos los valores de par√°metros especificados se exponen como atributos p√∫blicos. Jerarqu√≠a de objetos limitada S√≥lo los algoritmos est√°n representados por clases de Python; los conjuntos de datos se representan en formatos est√°ndar (matrices NumPy, Pandas DataFrames, matrices dispersas de SciPy) y los nombres de los par√°metros utilizan cadenas est√°ndar de Python.\nComposici√≥n Muchas tareas de aprendizaje autom√°tico se pueden expresar como secuencias de algoritmos m√°s fundamentales, y ScikitLearn hace uso de esto siempre que es posible.\nValores predeterminados sensatos Cuando los modelos requieren par√°metros especificados por el usuario, la biblioteca define un valor predeterminado apropiado."
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#b√°sicos-de-la-api",
    "href": "posts/Hyperparameters and Model Validation/index.html#b√°sicos-de-la-api",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "B√°sicos de la API",
    "text": "B√°sicos de la API\nPor lo general, los pasos para usar la API del estimador Scikit-Learn son los siguientes (repasaremos algunos ejemplos detallados en las secciones siguientes):\n\nElija una clase de modelo importando la clase de estimador adecuada de ScikitLearn.\nElija los hiperpar√°metros del modelo creando una instancia de esta clase con los valores deseados.\nOrganice los datos en una matriz de caracter√≠sticas y un vector objetivo siguiendo la discusi√≥n anterior.\nAjuste el modelo a sus datos llamando al m√©todo fit() de la instancia del modelo.\nAplique el modelo a nuevos datos:\n\n‚Ä¢ Para el aprendizaje supervisado, a menudo predecimos etiquetas para datos desconocidos usando el m√©todo predict().\n‚Ä¢ Para el aprendizaje no supervisado, a menudo transformamos o inferimos propiedades de los datos utilizando el m√©todo transform() o predict()."
  },
  {
    "objectID": "posts/Hyperparameters and Model Validation/index.html#ejemplo-de-aprendizaje-supervisado-regresi√≥n-lineal-simple",
    "href": "posts/Hyperparameters and Model Validation/index.html#ejemplo-de-aprendizaje-supervisado-regresi√≥n-lineal-simple",
    "title": "Hiperparametros y Modelos de Validaci√≥n",
    "section": "Ejemplo De Aprendizaje Supervisado: Regresi√≥n Lineal Simple",
    "text": "Ejemplo De Aprendizaje Supervisado: Regresi√≥n Lineal Simple\n\nimport numpy as np\n\n\nrng=np.random.RandomState(42)\nx=10+rng.rand(50)\ny=2*x-1+rng.rand(50)\nplt.scatter(x,y)\n\n&lt;matplotlib.collections.PathCollection at 0x1e7115f3c20&gt;\n\n\n\n\n\n\nEscojemos el modelo\n\n\nfrom sklearn.linear_model import LinearRegression\n\n\nEscogemos los hiperparametros\n\n\nmodel=LinearRegression(fit_intercept=True)\nmodel\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\nOrganizando los datos en variables independientes y variable dependiente\n\n\nX=x[:,np.newaxis]\nX.shape\n\n(50, 1)\n\n\n\nAjustando el modelo\n\n\nmodel.fit(X,y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\nmodel.coef_\n\narray([2.06607665])\n\n\n\nmodel.intercept_\n\n-1.1957940680607742\n\n\n\nPredicciendo data desconocida\n\n\nxfit=np.linspace(-1,11)\n\n\nXfit=xfit[:,np.newaxis]\nyfit=model.predict(Xfit)\n\n\nplt.scatter(x,y)\nplt.plot(xfit,yfit)"
  },
  {
    "objectID": "posts/Linear_Regression/index.html",
    "href": "posts/Linear_Regression/index.html",
    "title": "Regresi√≥n Lineal Simple",
    "section": "",
    "text": "En este post presentamos un ejemplo b√°sico de regresi√≥n lineal simple, es decir, el caso de ajustar una l√≠nea a datos \\(x,y\\).\nAntes que nada importamos las librerias necesarias\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nPrimeramente generamos unos puntos para \\(x\\) y para \\(y\\)\n\nrng=np.random.RandomState(42)\nx=18*rng.rand(40)\ny=1.5*x-3+rng.rand(40)\nplt.scatter(x,y)\nplt.show()\n\n\n\n\nAhora definimos los hiperpar√°metros de nuestro modelo\n\nLineal=LinearRegression(fit_intercept=True) # La regresi√≥n lineal es de la forma y=ax+b, donde b!=0\n\nDefinimos la variable \\(X\\)\n\nX=x[:,np.newaxis]\nX.shape\n\n(40, 1)\n\n\nNota: en este caso como estamos trabajando con datos simulados no es necesario definir \\(y\\) puesto que sklearn si nos permite ingresar ese array\nAhor ajustamos el modelo\n\nLineal.fit(X,y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\nObservemos el valor del coeficiente (\\(a\\))\n\nLineal.coef_\n\narray([1.50922213])\n\n\nObservemos el valor del intercepto (\\(b\\))\n\nLineal.intercept_\n\n-2.60022468062337\n\n\nProbemos el poder predictivo de nuestro modelo\n\nxfit=np.arange(17,22,0.5)\nXfit=xfit[:,np.newaxis]\nyfit=Lineal.predict(Xfit)\n\nAhora realizemos una visualizaci√≥n\n\ndef f(x):\n  return 1.51*x-2.6\n\nplt.scatter(x,y)\nplt.scatter(xfit,yfit,color='red')\nplt.plot(range(-1,22),[f(i) for i in range(-1,22)],color='cyan')\nplt.legend(['Datos modelo','Datos predichos','y=ax+b'])\nplt.show()"
  },
  {
    "objectID": "posts/naive_bayes/index.html",
    "href": "posts/naive_bayes/index.html",
    "title": "Naive Bayes Clasificaci√≥n",
    "section": "",
    "text": "En este post vamos a utilizar los datos iris para entrenar un modelo de clasificaci√≥n y ver que tan bien se puede predecir las etiquetas\nEn este caso para evitarnos particionar el conjunto a ‚Äúmano‚Äù utilizaremos la funci√≥n train_test_split\nPrieramente importamos las librerias necesarias\n\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\n\nluego importamos el conjunto de datos\n\niris=sb.load_dataset('iris')\nX_iris=iris.drop('species',axis=1)\ny_iris=iris['species']\n\nAhora creamos los datos de entrenamiento y validaci√≥n\n\nXtrain,Xtest,ytrain,ytest =train_test_split(X_iris,y_iris,random_state=1)\n\nAhora importamos el modelo que utilizaremos\n\nfrom sklearn.naive_bayes import GaussianNB\n\nDefinimos un nombre\n\nNB=GaussianNB()\n\najustamos el modelo\n\nNB.fit(Xtrain,ytrain)\n\nGaussianNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianNBGaussianNB()\n\n\npredecimos la data que no se utilizo para establecer los par√°metros del modelo\n\ny_NB=NB.predict(Xtest)\n\nAhora utilizando la m√©trica de exactitud (accurancy score) evaluaremos que tan bien predice el modelo que se ha creado\n\nfrom sklearn.metrics import accuracy_score\n\n\naccuracy_score(ytest,y_NB)\n\n0.9736842105263158\n\n\nVemos que con una exactitud del \\(97,4\\%\\) el modelo implementado puede etiquetar los datos requeridos."
  },
  {
    "objectID": "posts/2023-12-20-PCA/index.html",
    "href": "posts/2023-12-20-PCA/index.html",
    "title": "Analisis de Componentes Principales",
    "section": "",
    "text": "En este post se pretende reducir dimensiones de una cantidad de datos es decir encontrar una transformaci√≥n en la cu√°l se represente de mejor manera los datos reduciendo as√≠ su dimensi√≥n\nComo ya es costumbre primero importamos las librer√≠as necesarias\n\nimport seaborn as sb \nimport numpy as np\nfrom sklearn.decomposition import PCA\n\nImportemos los datos\n\niris=sb.load_dataset('iris')\nX_iris=iris.drop('species',axis=1)\ny_iris=iris['species']\n\nDefinimos el modelo\n\nACP=PCA(n_components=2)\n\nAjustamos el modelo\n\nACP.fit(X_iris)\n\nPCA(n_components=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PCAPCA(n_components=2)\n\n\ntransformamos la data\n\nX_2d=ACP.transform(X_iris)\n\nRealizamos una representaci√≥n gr√°fica\n\n#para facilitarnos el trabajo vamos a extender sobre el data iris los nuevos ejes encontrados\niris['PCA1']=X_2d[:,0]\niris['PCA2']=X_2d[:,1]\nsb.lmplot(x=\"PCA1\",y=\"PCA2\",hue='species',data=iris,fit_reg=False)"
  },
  {
    "objectID": "posts/2023-12-20-Clustering/index.html",
    "href": "posts/2023-12-20-Clustering/index.html",
    "title": "Gaussian Mixture Models",
    "section": "",
    "text": "En este post veremos un modelos de cluster\nComo ya es costumbre primero importamos las librerias necesarias\n\nimport seaborn as sb \nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nImportemos los datos\n\niris=sb.load_dataset('iris')\nX_iris=iris.drop('species',axis=1)\ny_iris=iris['species']\n\nDefinimos el modelo\n\nGauss=GaussianMixture(n_components=3,\ncovariance_type='full')\n\nAjustamos el modelo\n\nGauss.fit(X_iris)\n\nGaussianMixture(n_components=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianMixtureGaussianMixture(n_components=3)\n\n\nDeterminamos las etiquetas\n\ny_gmm=Gauss.predict(X_iris)\n\ngraficamente\n\niris.head()\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\niris['cluster']=y_gmm\nsb.lmplot(data=iris,x='sepal_length',y='petal_length',hue='species',col='cluster',fit_reg=False)"
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html",
    "href": "proyects/Tesis_JXBS/index.html",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "",
    "text": "El modelo de consumo y renta surge de manera casi natural cuando un individuo se plantea un escenario del tipo ¬øQu√© pasar√≠a si se destinara una parte de su renta a un fondo de ahorro?. Es as√≠ que se empieza con un planteamiento muy b√°sico en el que el individuo esperar√≠a que su ahorro lo ayude a afrontar crisis futuras. Sin embargo, esto es un poco ingenuo puesto que el individuo no tiene certeza de cuanto tiempo va a vivir, as√≠ como tampoco de si su ahorro lo ayudara en un momento de gran crisis. Es as√≠ que de manera natural se procede a generalizar la idea a un grupo de individuos, lo cual desencadena en lo siguiente ¬øTodos los individuos se comportan de una manera similar?. A partir de esto se ramifica dos situaciones, la primera, considerar que todos los individuos tienen un comportamiento similar y por tanto realizar modelos con datos de medias; la segunda, es considerar que los individuos tiene comportamientos diferentes y por tanto buscar cual es el modelo que mejor describe esta realidad.\n\n\nAl inicio de los a√±os \\(50\\), el modelo que predomino el comportamiento de consumo y que fue utilizado por los macroeconomistas se inspiro en la ‚Äúley fundamental de la psicolog√≠a‚Äù mencionada por (Keynes 1936) en la Teor√≠a general. A ese momento, las limitaciones emp√≠ricas y te√≥ricas del mencionado modelo se hicieron cada vez m√°s notorias. Desde un punto de vista te√≥rico, es dif√≠cil construir modelos coherentes basados en la optimizaci√≥n intertemporal del comportamiento que sean consistentes con la descripci√≥n de (Keynes 1936) en la ‚ÄúLey fundamental de la psicolog√≠a‚Äù. Desde el punto de vista emp√≠rico, parec√≠a que el punto de vista de Keynes era incompatible con una serie de hechos, tanto a macro y micro nivel. A nivel agregado, por ejemplo, seg√∫n (Orazio P. Attanasio y Weber 2010) se observ√≥ que la propensi√≥n marginal a consumir de la renta disponible fue menor en el corto plazo que a la larga. Por otro lado, en secciones cruzadas, las tasas de ahorro parecieron cambiar sistem√°ticamente con el nivel de rentas. Adem√°s, se observ√≥ que grupos de individuos con, niveles m√°s bajos de rentas en media, ten√≠an tasas de ahorro m√°s altas que otros grupos con niveles m√°s altos de renta en media esto se da en cualquier nivel de renta. Finalmente, se observ√≥ que las tasas de ahorro est√°n sistem√°ticamente relacionadas a los cambios en los rentas, siendo mayor para las personas que experimentas aumentos de rentas y menor para las personas que experimentan rentas que disminuyen (ver, Katona 1949).\nTodas estas observaciones contradec√≠an claramente las implicaciones del modelo keynesiano y condujeron a la formulaci√≥n de los modelos de ciclo de vida y de renta permanente (Modigliani y Brumberg 1980; Friedman 1957). Estos modelos combinaban consistencia te√≥rica en el sentido de que las opciones intertemporales de consumo y ahorro se enmarcaban dentro de un problema de optimizaci√≥n coherente con la capacidad de ajustar la mayor√≠a de los hechos mencionados en el p√°rrafo anterior.\nA nivel macro, es m√°s probable que las fluctuaciones a corto plazo de la renta disponible est√©n dominadas por la varianza de las perturbaciones temporales que se promediar√≠an a largo plazo (ver, Orazio P. Attanasio y Weber 2010).\nEl desarrollo de las ideas en las contribuciones iniciales de (Modigliani y Brumberg 1980; Friedman 1957) tambi√©n llev√≥ a la realizaci√≥n de otras implicaciones. En una versi√≥n simple del modelo del ciclo de vida, si las rentas tienen forma de joroba y disminuyen al momento de la jubilaci√≥n, los consumidores ahorraran cuando sean j√≥venes para respaldar el consumo en la √∫ltima parte de la vida y desahorraran cuando sean mayores. (Modigliani y Brumberg 1980) luego demostraron que este hecho puede explicar la correlaci√≥n entre el crecimiento agregado y el ahorro agregado: el crecimiento implica que, en un a√±o dado, las cohortes m√°s j√≥venes, que est√°n ahorrando, son ``m√°s ricas‚Äô‚Äô en t√©rminos de vida que las de mayor edad, que est√°n desahorrando. Cuanto mayor sea la tasa de crecimiento, mayor ser√° la diferencia de recursos entre los ahorradores y los desahorradores y, por lo tanto, mayor ser√° la tasa agregada de ahorro.\nDespu√©s de su desarrollo inicial, el otro paso importante en el desarrollo del modelo de ciclo de vida/renta permanente, que actualmente se usa como el modelo est√°ndar de la macroeconom√≠a moderna, fue un tratamiento riguroso de la incertidumbre. A fines de la d√©cada de 1970, las contribuciones de (Hall 1978, y; MaCurdy 1981, en el contexto de la oferta laboral) explot√≥ la idea de usar las condiciones de primer orden del problema de optimizaci√≥n intertemporal que enfrenta el consumidor para derivar implicaciones comprobables del modelo. Este enfoque, conocido como el enfoque de la ecuaci√≥n de Euler1, hace posible el an√°lisis emp√≠rico de un problema que es anal√≠ticamente intratable evitando la necesidad de derivar soluciones de forma cerrada. Esto se logra centr√°ndose en la esencia econ√≥mica del modelo: los consumidores, en el momento √≥ptimo, actuar√°n para mantener constante la utilidad marginal de la riqueza a lo largo del tiempo. La utilidad marginal de la riqueza es, al mismo tiempo, una estad√≠stica suficiente para las elecciones de los consumidores y, dadas sus propiedades din√°micas, puede ‚Äúdiferenciarse‚Äù de manera an√°loga al tratamiento de los efectos fijos en la econometr√≠a (Orazio P. Attanasio y Weber 2010).\n\n\n\n\n\nComo se mencion√≥ en la introducci√≥n, el modelo de ciclo de vida/renta permanente se desarroll√≥ para explicar algunos hechos sobre el consumo.\n\nEl gasto de consumo (no duradero) es menos vol√°til que la renta y la propensi√≥n marginal a consumir parece ser menor en el corto plazo que en el largo plazo. Estos ‚Äúmacro acontecimientos‚Äù siguen siendo v√°lidos y algunos tambi√©n se pueden encontrar en micro datos (como la variabilidad relativa del consumo y las rentas no duraderas, consulte, O. Attanasio 2000, y; O. P. Attanasio y Borella 2006).\nSi uno mira los datos de la Encuesta de Gastos del Consumidor (CEX) de los Estados Unidos, encuentra que la tasa de ahorro de los afrodescendientes es m√°s alta que la de los blancos en cualquier nivel de rentas, como se√±al√≥ (Friedman 1957). Se puede obtener evidencia similar en EE. UU. y el Reino Unido si se observan las tasas de ahorro por nivel de renta actual de otros grupos que difieren por el nivel de renta ‚Äúpermanente‚Äù, como los hogares encabezados por personas con diferentes niveles de educaci√≥n.\nAn√°logamente, si se consideran por separado los individuos cuyas rentas han aumentado y los individuos cuyas rentas han disminuido, la tasa de ahorro de estos √∫ltimos es menor que la de los primeros, como se√±alaron hace varios a√±os (Modigliani y Brumberg 2013), citando el trabajo de Margaret G. Reid.\nPatrones de ciclo de vida de baja frecuencia (Carroll y Summers 1991) muestran que los perfiles de rentas y consumos del de ciclo de vida se siguen mutuamente lo cual contradice una de las principales predicciones del modelo de ciclo de vida.\nFrecuencia del ciclo econ√≥mico (J. Y. Campbell y Mankiw 1989) encontraron que la regresi√≥n de los cambios del \\(\\log(Consumo)\\) agregado para USA sobre las tasas de \\(inter\\acute{e}s\\) y \\(\\Delta \\log(renta_d)\\), atrajo un coeficiente de \\(0.4\\) estad√≠sticamente diferente de cero aun cuando se instrumentaliza las variables. Atribuyen el resultado a la presencia de un gran n√∫mero de consumidores que siguen una ‚Äúregla general‚Äù y establecen su consumo igual o proporcional a su renta.\n(Hall y Mishkin 1982), usando micro data de USA sobre el consumo de alimentos del PSID encuentra una correlaci√≥n significativa entre los cambios en el consumo de alimentos y los cambios retardados en las rentas. Interpretan esta evidencia como indicativa de que alrededor del \\(20\\%\\) de los hogares establecen el consumo sobre la base de renta actual, es decir no siguen el modelo de ciclo de vida.\n(Zeldes 1989) utilizando los mismos datos que (Hall y Mishkin 1982), pero categorizando por el nivel de activos (bajo y alto) encuentra que el consumo del primer grupo est√° mas ligado a la renta que el del segundo grupo e interpreta esta evidencia como la posibilidad de que algunos consumidores se ven afectados por restricciones de liquidez y/o endeudamiento que no les permite fijar el consumo actual en el nivel deseado.\nSi se especifica un modelo de series de tiempo de consumo y renta y adem√°s se identifica las innovaciones permanentes a est√° ultima variable, el modelo predice que estas innovaciones deber√≠an traducirse uno a uno en consumo. Esto implica restricciones param√©tricas de ecuaciones cruzadas sobre la representaci√≥n \\(VAR\\) que se puede estimar. (J. Campbell y Deaton 1989; West 1988; Gali 1991; Hansen, Roberds, y Sargent 1991), se√±alaron las restricciones mencionadas y utilizando datos agregados de series temporales concluyen que el consumo puede ser demasiado suave en el sentido de que no reacciona lo suficiente para innovaciones en el componente permanente de la renta.\n(O. Attanasio y Pavoni 2008), usando micro datos encuentran Exceso de suavidad (Una excepci√≥n es (Deaton 1992))\n\n\n\n\n\n(Deaton y Paxson 1994), notan que en un modelo de ciclo de vida, si la renta tiene ra√≠z unitaria (i.e es \\(I(1)\\) ^[Las series integradas son un caso particular de series no estacionarias. Se dice que una serie temporal \\(x_t\\) es integrada de orden \\(d\\), \\(I(d)\\), cuando es necesario diferenciarla \\(d\\) veces para convertirla en estacionaria (Engle y Granger 1987)) la secci√≥n cruzada del consumo aumenta con el tiempo2, Concluyen que a medida que se acumulen las innovaciones, la distribuci√≥n transversal del consumo se amplia con la edad.\n(Battistin, Blundell, y Lewbel 2009) utilizan un argumento similar para explicar una notable regularidad emp√≠rica: la distribuci√≥n de la secci√≥n cruzada del consumo parece aproximarse muy bien a una \\(\\log Normal\\). Bajo una versi√≥n est√°ndar del modelo de ciclo de vida, a cualquier edad el ‚Äú\\(\\log consumo_t=\\log consumo_{t-1}+u_t\\)‚Äù 3 y por lo tanto, por sustituci√≥n recursiva, se obtiene que el \\(log(consumo)\\) est√° dado por la suma de innovaciones desde el comienzo de la vida hasta la era actual4.\n(Blundell y Preston 1998), bajo un supuesto de mercado espec√≠fico, muestran que la evoluci√≥n relativa del consumo y la desigualdad de la renta pueden utilizarse para identificar variaciones permanentes y transitorias del ingreso y por lo tanto la diferencia entre el aumento de la varianza de la secci√≥n cruzada de la renta y la del consumo identificar√° los cambios en la varianza de la secci√≥n cruzada de la renta transitoria.\n(Deaton y Paxson 1994; Jappelli y Pistaferri 2006), hallan evidencia de que dada una distribuci√≥n inicial del consumo (sin importar c√≥mo se determine) en presencia de un riesgo compartido perfecto esa distribuci√≥n debe permanecer constante. Por un lado, (Deaton y Paxson 1994), notaron eso en una nota al pie y presentaron evidencia sobre la evoluci√≥n de secci√≥n cruzada del consumo como un rechazo del modelo de mercado completo. Por otro lado, (Jappelli y Pistaferri 2006), explotan esa idea al observar expl√≠citamente los movimientos en la clasificaci√≥n relativa en la distribuci√≥n del consumo en una encuesta italiana5\n(O. Attanasio y Davis 1996) al observar la evoluci√≥n del consumo relativo en diferentes grupos educativos y relacionado con cambios en los cambios salariales relativos e interpretan la evidencia de fuerte correlaci√≥n en bajas frecuencias entre estas dos variables como evidencia en contra de la hip√≥tesis del mercado completo. No pueden rechazar la hip√≥tesis de que a frecuencias relativamente altos (como un a√±o) no existe una relaci√≥n entre el consumo y los cambios salariales relativos6"
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#revisi√≥n-bibliogr√°fica",
    "href": "proyects/Tesis_JXBS/index.html#revisi√≥n-bibliogr√°fica",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "",
    "text": "Al inicio de los a√±os \\(50\\), el modelo que predomino el comportamiento de consumo y que fue utilizado por los macroeconomistas se inspiro en la ‚Äúley fundamental de la psicolog√≠a‚Äù mencionada por (Keynes 1936) en la Teor√≠a general. A ese momento, las limitaciones emp√≠ricas y te√≥ricas del mencionado modelo se hicieron cada vez m√°s notorias. Desde un punto de vista te√≥rico, es dif√≠cil construir modelos coherentes basados en la optimizaci√≥n intertemporal del comportamiento que sean consistentes con la descripci√≥n de (Keynes 1936) en la ‚ÄúLey fundamental de la psicolog√≠a‚Äù. Desde el punto de vista emp√≠rico, parec√≠a que el punto de vista de Keynes era incompatible con una serie de hechos, tanto a macro y micro nivel. A nivel agregado, por ejemplo, seg√∫n (Orazio P. Attanasio y Weber 2010) se observ√≥ que la propensi√≥n marginal a consumir de la renta disponible fue menor en el corto plazo que a la larga. Por otro lado, en secciones cruzadas, las tasas de ahorro parecieron cambiar sistem√°ticamente con el nivel de rentas. Adem√°s, se observ√≥ que grupos de individuos con, niveles m√°s bajos de rentas en media, ten√≠an tasas de ahorro m√°s altas que otros grupos con niveles m√°s altos de renta en media esto se da en cualquier nivel de renta. Finalmente, se observ√≥ que las tasas de ahorro est√°n sistem√°ticamente relacionadas a los cambios en los rentas, siendo mayor para las personas que experimentas aumentos de rentas y menor para las personas que experimentan rentas que disminuyen (ver, Katona 1949).\nTodas estas observaciones contradec√≠an claramente las implicaciones del modelo keynesiano y condujeron a la formulaci√≥n de los modelos de ciclo de vida y de renta permanente (Modigliani y Brumberg 1980; Friedman 1957). Estos modelos combinaban consistencia te√≥rica en el sentido de que las opciones intertemporales de consumo y ahorro se enmarcaban dentro de un problema de optimizaci√≥n coherente con la capacidad de ajustar la mayor√≠a de los hechos mencionados en el p√°rrafo anterior.\nA nivel macro, es m√°s probable que las fluctuaciones a corto plazo de la renta disponible est√©n dominadas por la varianza de las perturbaciones temporales que se promediar√≠an a largo plazo (ver, Orazio P. Attanasio y Weber 2010).\nEl desarrollo de las ideas en las contribuciones iniciales de (Modigliani y Brumberg 1980; Friedman 1957) tambi√©n llev√≥ a la realizaci√≥n de otras implicaciones. En una versi√≥n simple del modelo del ciclo de vida, si las rentas tienen forma de joroba y disminuyen al momento de la jubilaci√≥n, los consumidores ahorraran cuando sean j√≥venes para respaldar el consumo en la √∫ltima parte de la vida y desahorraran cuando sean mayores. (Modigliani y Brumberg 1980) luego demostraron que este hecho puede explicar la correlaci√≥n entre el crecimiento agregado y el ahorro agregado: el crecimiento implica que, en un a√±o dado, las cohortes m√°s j√≥venes, que est√°n ahorrando, son ``m√°s ricas‚Äô‚Äô en t√©rminos de vida que las de mayor edad, que est√°n desahorrando. Cuanto mayor sea la tasa de crecimiento, mayor ser√° la diferencia de recursos entre los ahorradores y los desahorradores y, por lo tanto, mayor ser√° la tasa agregada de ahorro.\nDespu√©s de su desarrollo inicial, el otro paso importante en el desarrollo del modelo de ciclo de vida/renta permanente, que actualmente se usa como el modelo est√°ndar de la macroeconom√≠a moderna, fue un tratamiento riguroso de la incertidumbre. A fines de la d√©cada de 1970, las contribuciones de (Hall 1978, y; MaCurdy 1981, en el contexto de la oferta laboral) explot√≥ la idea de usar las condiciones de primer orden del problema de optimizaci√≥n intertemporal que enfrenta el consumidor para derivar implicaciones comprobables del modelo. Este enfoque, conocido como el enfoque de la ecuaci√≥n de Euler1, hace posible el an√°lisis emp√≠rico de un problema que es anal√≠ticamente intratable evitando la necesidad de derivar soluciones de forma cerrada. Esto se logra centr√°ndose en la esencia econ√≥mica del modelo: los consumidores, en el momento √≥ptimo, actuar√°n para mantener constante la utilidad marginal de la riqueza a lo largo del tiempo. La utilidad marginal de la riqueza es, al mismo tiempo, una estad√≠stica suficiente para las elecciones de los consumidores y, dadas sus propiedades din√°micas, puede ‚Äúdiferenciarse‚Äù de manera an√°loga al tratamiento de los efectos fijos en la econometr√≠a (Orazio P. Attanasio y Weber 2010)."
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#acontecimientos",
    "href": "proyects/Tesis_JXBS/index.html#acontecimientos",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "",
    "text": "Como se mencion√≥ en la introducci√≥n, el modelo de ciclo de vida/renta permanente se desarroll√≥ para explicar algunos hechos sobre el consumo.\n\nEl gasto de consumo (no duradero) es menos vol√°til que la renta y la propensi√≥n marginal a consumir parece ser menor en el corto plazo que en el largo plazo. Estos ‚Äúmacro acontecimientos‚Äù siguen siendo v√°lidos y algunos tambi√©n se pueden encontrar en micro datos (como la variabilidad relativa del consumo y las rentas no duraderas, consulte, O. Attanasio 2000, y; O. P. Attanasio y Borella 2006).\nSi uno mira los datos de la Encuesta de Gastos del Consumidor (CEX) de los Estados Unidos, encuentra que la tasa de ahorro de los afrodescendientes es m√°s alta que la de los blancos en cualquier nivel de rentas, como se√±al√≥ (Friedman 1957). Se puede obtener evidencia similar en EE. UU. y el Reino Unido si se observan las tasas de ahorro por nivel de renta actual de otros grupos que difieren por el nivel de renta ‚Äúpermanente‚Äù, como los hogares encabezados por personas con diferentes niveles de educaci√≥n.\nAn√°logamente, si se consideran por separado los individuos cuyas rentas han aumentado y los individuos cuyas rentas han disminuido, la tasa de ahorro de estos √∫ltimos es menor que la de los primeros, como se√±alaron hace varios a√±os (Modigliani y Brumberg 2013), citando el trabajo de Margaret G. Reid.\nPatrones de ciclo de vida de baja frecuencia (Carroll y Summers 1991) muestran que los perfiles de rentas y consumos del de ciclo de vida se siguen mutuamente lo cual contradice una de las principales predicciones del modelo de ciclo de vida.\nFrecuencia del ciclo econ√≥mico (J. Y. Campbell y Mankiw 1989) encontraron que la regresi√≥n de los cambios del \\(\\log(Consumo)\\) agregado para USA sobre las tasas de \\(inter\\acute{e}s\\) y \\(\\Delta \\log(renta_d)\\), atrajo un coeficiente de \\(0.4\\) estad√≠sticamente diferente de cero aun cuando se instrumentaliza las variables. Atribuyen el resultado a la presencia de un gran n√∫mero de consumidores que siguen una ‚Äúregla general‚Äù y establecen su consumo igual o proporcional a su renta.\n(Hall y Mishkin 1982), usando micro data de USA sobre el consumo de alimentos del PSID encuentra una correlaci√≥n significativa entre los cambios en el consumo de alimentos y los cambios retardados en las rentas. Interpretan esta evidencia como indicativa de que alrededor del \\(20\\%\\) de los hogares establecen el consumo sobre la base de renta actual, es decir no siguen el modelo de ciclo de vida.\n(Zeldes 1989) utilizando los mismos datos que (Hall y Mishkin 1982), pero categorizando por el nivel de activos (bajo y alto) encuentra que el consumo del primer grupo est√° mas ligado a la renta que el del segundo grupo e interpreta esta evidencia como la posibilidad de que algunos consumidores se ven afectados por restricciones de liquidez y/o endeudamiento que no les permite fijar el consumo actual en el nivel deseado.\nSi se especifica un modelo de series de tiempo de consumo y renta y adem√°s se identifica las innovaciones permanentes a est√° ultima variable, el modelo predice que estas innovaciones deber√≠an traducirse uno a uno en consumo. Esto implica restricciones param√©tricas de ecuaciones cruzadas sobre la representaci√≥n \\(VAR\\) que se puede estimar. (J. Campbell y Deaton 1989; West 1988; Gali 1991; Hansen, Roberds, y Sargent 1991), se√±alaron las restricciones mencionadas y utilizando datos agregados de series temporales concluyen que el consumo puede ser demasiado suave en el sentido de que no reacciona lo suficiente para innovaciones en el componente permanente de la renta.\n(O. Attanasio y Pavoni 2008), usando micro datos encuentran Exceso de suavidad (Una excepci√≥n es (Deaton 1992))\n\n\n\n\n\n(Deaton y Paxson 1994), notan que en un modelo de ciclo de vida, si la renta tiene ra√≠z unitaria (i.e es \\(I(1)\\) ^[Las series integradas son un caso particular de series no estacionarias. Se dice que una serie temporal \\(x_t\\) es integrada de orden \\(d\\), \\(I(d)\\), cuando es necesario diferenciarla \\(d\\) veces para convertirla en estacionaria (Engle y Granger 1987)) la secci√≥n cruzada del consumo aumenta con el tiempo2, Concluyen que a medida que se acumulen las innovaciones, la distribuci√≥n transversal del consumo se amplia con la edad.\n(Battistin, Blundell, y Lewbel 2009) utilizan un argumento similar para explicar una notable regularidad emp√≠rica: la distribuci√≥n de la secci√≥n cruzada del consumo parece aproximarse muy bien a una \\(\\log Normal\\). Bajo una versi√≥n est√°ndar del modelo de ciclo de vida, a cualquier edad el ‚Äú\\(\\log consumo_t=\\log consumo_{t-1}+u_t\\)‚Äù 3 y por lo tanto, por sustituci√≥n recursiva, se obtiene que el \\(log(consumo)\\) est√° dado por la suma de innovaciones desde el comienzo de la vida hasta la era actual4.\n(Blundell y Preston 1998), bajo un supuesto de mercado espec√≠fico, muestran que la evoluci√≥n relativa del consumo y la desigualdad de la renta pueden utilizarse para identificar variaciones permanentes y transitorias del ingreso y por lo tanto la diferencia entre el aumento de la varianza de la secci√≥n cruzada de la renta y la del consumo identificar√° los cambios en la varianza de la secci√≥n cruzada de la renta transitoria.\n(Deaton y Paxson 1994; Jappelli y Pistaferri 2006), hallan evidencia de que dada una distribuci√≥n inicial del consumo (sin importar c√≥mo se determine) en presencia de un riesgo compartido perfecto esa distribuci√≥n debe permanecer constante. Por un lado, (Deaton y Paxson 1994), notaron eso en una nota al pie y presentaron evidencia sobre la evoluci√≥n de secci√≥n cruzada del consumo como un rechazo del modelo de mercado completo. Por otro lado, (Jappelli y Pistaferri 2006), explotan esa idea al observar expl√≠citamente los movimientos en la clasificaci√≥n relativa en la distribuci√≥n del consumo en una encuesta italiana5\n(O. Attanasio y Davis 1996) al observar la evoluci√≥n del consumo relativo en diferentes grupos educativos y relacionado con cambios en los cambios salariales relativos e interpretan la evidencia de fuerte correlaci√≥n en bajas frecuencias entre estas dos variables como evidencia en contra de la hip√≥tesis del mercado completo. No pueden rechazar la hip√≥tesis de que a frecuencias relativamente altos (como un a√±o) no existe una relaci√≥n entre el consumo y los cambios salariales relativos6"
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#ecuaci√≥n-de-euler-del-consumo",
    "href": "proyects/Tesis_JXBS/index.html#ecuaci√≥n-de-euler-del-consumo",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Ecuaci√≥n de Euler del consumo",
    "text": "Ecuaci√≥n de Euler del consumo\n(Parker 2007) Dice que, considerando un agente de vida infinita que elige una variable de control \\(C\\) en cada per√≠odo \\(t\\) para maximizar un objetivo intertemporal: \\(\\sum\\limits_{t=1}^\\infty \\beta u(C_t)\\), donde \\(u(C_t)\\) representa el flujo de pago en \\(t\\), \\(u'&gt;0,~u''&lt;0\\), y \\(\\beta\\) es el factor de descuento, \\(0&lt;\\beta&lt;1\\). El agente se enfrenta a una restricci√≥n presupuestaria de valor presente: \\(\\sum\\limits_{t=1} R^{1-t}C_t\\leq W_1\\), donde \\(R\\) es la tasa de inter√©s bruta (\\(R=1+r\\), donde \\(r\\) es la tasa de inter√©s) y \\(W_1\\) es dado (mas adelante veremos que es el patrimonio). Por la teor√≠a de optimizaci√≥n, si una trayectoria de tiempo del control es √≥ptima, un aumento marginal en el control en cualquier \\(t\\), \\(dC_t\\), debe tener beneficios en \\(t+1\\) de la misma cantidad de valor presente, \\(-RdC_t\\), as√≠: \\(\\beta^{t-1}u'(C_t)dC_t-\\beta^tu'(C_{t+1})RdC_t=0\\). Reorganizando obtenemos las ecuaciones de Euler: \\(u'(C_t)=\\beta Ru'(C_{t+1}),\\) para \\(t=1,2,3,\\dots.\\)"
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#modelo-te√≥rico-el-modelo-de-ciclo-de-vida",
    "href": "proyects/Tesis_JXBS/index.html#modelo-te√≥rico-el-modelo-de-ciclo-de-vida",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Modelo Te√≥rico ‚ÄúEL modelo de ciclo de vida‚Äù",
    "text": "Modelo Te√≥rico ‚ÄúEL modelo de ciclo de vida‚Äù\n\nPreferencias\nLa versi√≥n del modelo que se considera es aquella en la que una unidad de consumo maximiza la utilidad esperada en un intervalo finito sujeto a un conjunto de restricciones. \\[\n\\max E_t \\left[ \\sum_{j=0}^{T-t}\\beta_{t+j}U\\left(C_{t+j},z_{t+j},v_{t+j}\\right) \\right]\n\\tag{1}\\] donde, \\(C\\) representa el ‚Äúconsumo‚Äù, \\(z\\) es un vector de variables observables que afecta a la utilidad, \\(v\\) es un vector para factores no observables que afectan a la utilidad, y \\(\\beta\\) es un factor de descuento.\nsujeto a las siguientes restricciones\n\\[\nW_{t+j+1}=W_{t+j}\\left(1+R_{t+j}^\\ast\\right) +y_{t+j} -C_{t+j},\n\\tag{2}\\]\n\\[\nW_{t+j}=\\sum_{i=1}^N A_{t+j}^i,\n\\tag{3}\\]\n\\[\nR_{t+j}^\\ast=\\sum_{i=0}^N \\omega_{t+j}^i R_{t+j}^i,\n\\tag{4}\\]\n\\[\nW_T\\geq0\n\\tag{5}\\]\ndonde, \\(W\\) es el patrimonio neto y su rendimiento, \\(\\omega\\) son las ponderaciones de la cartera, \\(R\\) son los rendimientos, \\(A\\) son los activos y \\(y\\) es el ingreso.\nLa restricci√≥n Ecuaci√≥n¬†2 es una restricci√≥n presupuestaria gen√©rica donde el valor neto aparece junto con su retorno, ingreso y consumo7. Las restricciones Ecuaci√≥n¬†3 y Ecuaci√≥n¬†4 definen el patrimonio neto, \\(W\\), y su rendimiento \\(-\\omega_{t+j}^i\\): son las acciones (o ponderaciones) de la cartera. El rendimiento del patrimonio neto est√° dado por el promedio ponderado de los rendimientos individuales, \\(R_{t+j}^i\\). Se supone que estos rendimientos no dependen de la posici√≥n neta que tome el consumidor sobre cada uno de estos activos, \\(A_{t+j}^i\\). (ver , Orazio P. Attanasio y Weber 2010)\nLa restricci√≥n Ecuaci√≥n¬†5 da el l√≠mite para el patrimonio neto total en el periodo \\(T\\). El consumidor tiene que morir sin deuda, es decir tiene que pagar su deuda con probabilidad uno8.\nEn esta formulaci√≥n se supone varias restricciones importantes: * El consumidor maximiza la utilidad esperada. * Las preferencias son aditivamente separables a lo largo del tiempo * Impl√≠citamente es posible anotar la utilidad como una funci√≥n de una sola mercanc√≠a. Esta practica presupone un teorema de agregaci√≥n del tipo estudiado por (Gorman 1959).\nEl problema formulado anteriormente es capaz de abarcar diferentes versiones del modelo que se han considerado en la literatura. En particular, tratamos como casos especiales el modelo est√°ndar de ingresos permanentes/ciclo de vida con preferencias cuadr√°ticas, el llamado ahorro de existencias reguladoras, as√≠ como versiones flexibles del modelo (con un papel importante para la demograf√≠a y la oferta laboral) que se han ajustado a los datos.\nComencemos con un caso en el que la funci√≥n de consumo se puede derivar anal√≠ticamente. Sea la utilidad cuadr√°tica en \\(C\\) (y aditivamente separable en sus otros argumentos \\(z\\)), y suponga que al menos un activo financiero se negocia libremente y produce un rendimiento real fijo, igual al par√°metro de referencia temporal constante \\(\\frac{1-\\beta}{\\beta}\\). La condici√≥n de primer orden con respecto al consumo, o ecuaci√≥n de Euler, implica que el consumo es paseo aleatorio. \\[\n     E(C_{t+1}|I_t )=C_t\n\\tag{6}\\]\ndonde \\(I_t\\), denota la informaci√≥n disponible al instante \\(t\\) . En efecto notemos que al ser la funci√≥n de utilidad cuadr√°tica en \\(C\\) y aditivamente separable en sus otros argumentos (Hall 1978) no dice que se cumple exactamente \\(C_{t+1}=\\beta_0 +\\gamma C_t -\\varepsilon_{t+1}\\) de donde tomando la Esperanza al tiempo \\(t\\) y dado que se produce un rendimiento real fijo, tenemos la Ecuaci√≥n¬†6.\nen \\(t\\), el consumidor escoge \\(C_t\\) tal que maximiza \\[\n     \\beta_0 U(C_t,z_t,v_t)+ E_t \\sum_{\\tau=t+1}^{T-t} \\beta_{\\tau+j}U(C_\\tau,z_\\tau,v_\\tau)\n\\tag{7}\\] sujeto a \\[\n    W_{\\tau+j}=W_{\\tau-1+j} \\left(1+R_{\\tau-1+j}^\\ast \\right) + y_{\\tau-1+j}-C_{\\tau-1+j}\n\\tag{8}\\] la estrategia secuencial √≥ptima tiene la forma \\[\n    C_t=g_t(w_\\tau,w_{\\tau-1},\\dots,w_0,A_0)\n\\]\nconsiderando una variaci√≥n desde esta estrategia\nSi los consumidores tienen expectativas racionales, entonces: \\[\n     C_{t+1}=C_t+\\varepsilon_{t+1} \\qquad E\\left( \\varepsilon_{t+1}|W_t \\right)=0\n\\tag{9}\\] para todas las variables \\(W\\) conocidas al instante \\(t\\). La ecuaci√≥n Ecuaci√≥n¬†9 se puede utilizar para derivar una funci√≥n de consumo, en el caso de que no exista ning√∫n tipo otro activo disponible para el consumidor (como en, Bewley 1977) y la √∫nica variable estoc√°stica es la renta del trabajo. Sustituyendo en Ecuaci√≥n¬†9 en las restricciones presupuestarias, (Flavin 1981) muestra que el consumo se iguala a la renta permanente, definido como la tasa de inter√©s multiplicada por el valor presente de los ingresos actuales y futuros esperados:\n\\[\n     C_t=\\frac{r}{1+r}A_t +\\frac{r}{1+r}\\sum_{k=0}^\\infty E\\left(y_{t+k} | I_t\\right)\n\\tag{10}\\]\nLa ecuaci√≥n Ecuaci√≥n¬†10 se deriva para el caso especial de vida infinita, pero se puede derivar una extensi√≥n a la vida finita."
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#otro-modelo-de-consumo",
    "href": "proyects/Tesis_JXBS/index.html#otro-modelo-de-consumo",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Otro Modelo de Consumo",
    "text": "Otro Modelo de Consumo\nUna vez que tenemos estas definiciones podemos entonces incluir que si se sigue a (J. Y. Campbell 1987) y se define el ahorro como \\[\n    s_t=\\frac{rA_t}{1+r} +y_t -C_t\n\\tag{11}\\]\nAhora si \\(P(L) y_t=a+\\zeta_t\\), donde \\(P(L)\\) es un polinomio en el operador de retardos y \\(\\zeta_t\\) es un ruido blanco. En este caso la ecuaci√≥n Ecuaci√≥n¬†10 implica (Flavin 1981) que: \\[\n    P\\left(\\frac{1}{1+r}\\right)\\Delta C_{t+1}= \\frac{r}{1+r}\\zeta_{t+1}\n\\tag{12}\\]\nluego podemos reescribir Ecuaci√≥n¬†12 como: \\[\n    s_t=- \\sum_{k=1}^\\infty (1+r)^{-k} E\\left(\\Delta y_{t+k}|I_t \\right)\n\\tag{13}\\]\nLa ecuaci√≥n Ecuaci√≥n¬†13 muestra que los individuos deber√≠an ‚Äúahorrar para tiempos dif√≠ciles‚Äù (los ingresos futuros caen), y se mantiene (por la ley de las proyecciones iteradas) incluso si consideramos las expectativas condicionadas a un subconjunto de la informaci√≥n utilizada por los agentes econ√≥micos, como el pasado. ingreso y ahorro.\n\nProposici√≥n 1 Si \\(C_t\\) es un paseo aleatorio y adem√°s los consumidores tienen expectativas racionales y por otro lado \\(Y_t\\sim AR(1)\\) y adem√°s \\(Y_t\\sim I(1)\\) entonces: \\[\nC_{t+1}=\\frac{1}{1- \\eta}C_t +\\frac{\\eta}{1-\\eta} y_{t+1} +\\frac{\\eta^2}{1-\\eta}A_{t+1}\n\\tag{14}\\] en el caso de no tener informaci√≥n disponible sobre \\(\\eta\\), donde \\(\\eta\\) es la raz√≥n entre la tasa de inter√©s pasada y la tasa de inter√©s actual, y no disponer informaci√≥n del activo \\(A_{t+1}\\), el modelo puedo escribirse como \\[\n    C_{t+1}=aC_t+bY_{t+1}+ u_{t+1}\n\\tag{15}\\] donde \\(u_{t+1}\\) denotar√≠a la innovaci√≥n al tiempo \\(t+1\\)"
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#revisi√≥n-de-los-datos",
    "href": "proyects/Tesis_JXBS/index.html#revisi√≥n-de-los-datos",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Revisi√≥n de los datos",
    "text": "Revisi√≥n de los datos\nEn esta secci√≥n se empezara con el an√°lisis de las series de datos obtenidos del Banco Mundial las cuales son Households and NPISHs Final consumption expenditure per capita (constant 2015 US$) [NE.CON.PRVT.PC.KD] de los cuales se seleccionaran 14 pa√≠ses los cuales no tienen perdida de informaci√≥n. Estos pa√≠ses son: Bolivia, Brasil, Chile, Colombia, Costa Rica, Ecuador, Guatemala, Honduras, M√©xico, Nicaragua, Panam√°, Paraguay, Per√∫, y Rep√∫blica Dominicana.\nEn esta secci√≥n Hablaremos un poco de la comunidad andina que es de la cual se tiene conocimiento relevante en cuanto a su historia. La comunidad andina (CAN) esta integrada por los siguientes pa√≠ses: Bolivia, Colombia, Ecuador y Per√∫\n\nBolivia\n\n\n\n\n\n\n\n(a) Original\n\n\n\n\n\n\n\n(b) Corregida\n\n\n\n\nFigura¬†1: Serie para Bolivia original y corregida por software TRAMO/SEATS9\n\n\n\n\n\nFigura¬†2: Serie de irregularidades para Bolivia\n\n\nEn la figura Figura¬†2 se observa que la serie presenta irregularidades que se describen a continuaci√≥n:\n\n\\(1962\\)\n\\(1964\\) El gobierno se vio interrumpido por medio de un golpe militar, a partir de lo cual Bolivia habr√≠a de vivir dictaduras.\n\\(1972\\) Presencia de una dictadura en el gobierno y contrato de venta de gas a Argentina.\n\\(1977\\) Extraordinario nivel de precios de las materias primas (el esta√±o lleg√≥ a cotizarse en ocho d√≥lares la libra Ô¨Åna) y una gran apertura de cr√©ditos internacionales.\n\nEn la figura Figura¬†1 (b) se puede observar que la serie posee cierta tendencia que en principio debe ser estoc√°stica puesto que la poblaci√≥n y el desarrollo sigue en crecimiento.\n\n\nColombia\n\n\n\n\n\n\n\n(a) Original\n\n\n\n\n\n\n\n(b) Corregida\n\n\n\n\nFigura¬†3: Serie para Colombia original y corregida por software TRAMO/SEATS\n\n\n\n\n\nFigura¬†4: Serie de irregularidades para Colombia\n\n\nEn la figura Figura¬†4} se observa que la serie presenta irregularidades que se describen a continuaci√≥n\n\n\\(1964\\) Aparecen las FARC ,quienes aprobaron en su constituci√≥n un programa agrario que pretende la entrega gratuita de las tierras a los campesinos\n\\(1965\\) Empiezan los ataques de las guerrillas mismo que se extienden hasta estos d√≠as.\n\\(1992\\) Dr√°sticos recortes de energ√≠a en este pa√≠s, mismos que acarrearon perdidas millonarias.\n\\(1998\\) Se crea la ‚ÄúZona de distensi√≥n‚Äù e inicia el proceso de paz con las guerrillas.\n\\(1999\\) Debido a la gran cantidad de demandas que se interpusieron frente a la voracidad de los bancos y contra el refinado mecanismo del UPAC, el cual estaf√≥ a quienes se arriesgaron a endeudarse para tener casa, la Corte Constitucional resolvi√≥ acabarlo con la sentencia C-700\n\\(2019\\)\n\\(2020\\) COVID\n\n\n\nEcuador\n\n\n\n\n\n\n\n(a) Original\n\n\n\n\n\n\n\n(b) Corregida\n\n\n\n\nFigura¬†5: Serie para Colombia original y corregida por software TRAMO/SEATS\n\n\n\n\n\nFigura¬†6: Serie de irregularidades para Ecuador\n\n\nEn la figura Figura¬†6} se observa que la serie presenta irregularidades que se describen a continuaci√≥n:\n\n\\(1973\\) La apropiaci√≥n de los beneficios del petr√≥leo ‚Äúla renta petrolera‚Äù se constituy√≥ en objetivo de disputa de grupos sociales y organizaciones pol√≠ticas.\n\\(1998\\) La permisividad social a favor de monopolios y oligopolios10\n\\(1999\\) Feriado Bancario\n\n\n\nPer√∫\n\n\n\n\n\n\n\n(a) Original\n\n\n\n\n\n\n\n(b) Corregida\n\n\n\n\nFigura¬†7: Serie para Colombia original y corregida por software TRAMO/SEATS\n\n\n\n\n\nFigura¬†8: Serie de irregularidades para Ecuador\n\n\nEn la figura Figura¬†8 se observa que la serie presenta irregularidades que se describen a continuaci√≥n:\n\n\\(1983\\) Fen√≥meno del ni√±o y ca√≠da del precio de los metales.\n\\(1985\\) El sol fue reemplazado por el inti con un valor de \\(1000\\) soles (devaluaci√≥n de la moneda).\n\\(1987\\) Se empieza a sentir los efectos de las pol√≠ticas intervencionistas implementadas un a√±os atr√°s.\n\\(1989\\) Devaluaci√≥n del inti\n\nA continuaci√≥n en la figura Figura¬†9 presentamos las gr√°ficas de Consumo y Renta para cada uno de los pa√≠ses de Latinoam√©rica y Caribe seleccionados para este estudio.\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\n\n\n(g)\n\n\n\n\n\n\n\n(h)\n\n\n\n\n\n\n\n\n\n(i)\n\n\n\n\n\n\n\n(j)\n\n\n\n\n\n\n\n\n\n(k)\n\n\n\n\n\n\n\n(l)\n\n\n\n\n\n\n\n\n\n(m)\n\n\n\n\n\n\n\n(n)\n\n\n\n\nFigura¬†9: Gr√°fica de Series Consumo y Renta para los 14 pa√≠ses de Latino√°merica y Caribe\n\n\nEn la tabla Tabla¬†1 se realiza el contraste de Dickey-fuller aumentado (ADF) para las series corregidas.\n\n\nTabla¬†1: Contraste de ra√≠z unitaria Dickey Fuller aumentado\n\n\nPa√≠s\nRaiz Unitaria\n\\(p\\)-value\nlags\n\n\n\n\n\nRenta\n\n\n\n\nBolivia\nsi\n0,9861\n1\n\n\nBrasil\nsi\n0,9818\n1\n\n\nChile\nsi\n1,0000\n0\n\n\nColombia\nsi\n1,0000\n0\n\n\nCosta Rica\nsi\n1,0000\n0\n\n\nEcuador\nsi\n0,9680\n1\n\n\nGuatemala\nsi\n0,9965\n1\n\n\nHonduras\nsi\n0,9979\n0\n\n\nM√©xico\nsi\n0,9945\n0\n\n\nNicaragua\nsi\n0,6621\n1\n\n\nPanam√°\nsi\n0,9995\n0\n\n\nParaguay\nsi\n0,9966\n1\n\n\nPer√∫\nsi\n0,9830\n1\n\n\nR. Dominicana\nsi\n1,0000\n1\n\n\n\nConsumo\n\n\n\n\nBolivia\nsi\n0,9947\n1\n\n\nBrasil\nsi\n0,9982\n0\n\n\nChile\nsi\n1,0000\n0\n\n\nColombia\nsi\n1,0000\n0\n\n\nCosta Rica\nsi\n0,9978\n1\n\n\nEcuador\nsi\n0,9902\n0\n\n\nGuatemala\nsi\n0,9990\n1\n\n\nHonduras\nsi\n0,9998\n1\n\n\nM√©xico\nsi\n0,9789\n1\n\n\nNicaragua\nsi\n0,6414\n1\n\n\nPanam√°\nsi\n0,9975\n0\n\n\nParaguay\nsi\n1,0000\n0\n\n\nPer√∫\nsi\n0,9604\n1\n\n\nR. Dominicana\nsi\n1,0000\n0\n\n\n\n\nEn la tabla Tabla¬†1 se ha realizado el contraste ADF para cada una de las series tanto de Renta (PIB) como de Consumo (Consumo familiar). Es as√≠ que de manera general tenemos que para todos las series.\nDada la hip√≥tesis nula de no estacionariedad frente a la alternativa de estacionariedad, El estad√≠stico de contraste de ADF para el caso sin constante para el cual su distribuci√≥n se encuentra tabulada por Dickey Fuller. Entonces para un nivel de significancia del \\(\\alpha=0.05\\) puesto que el valor \\(p\\) del estad√≠stico es mayor que \\(\\alpha\\), No se rechazo la hip√≥tesis nula de no estacionariedad.\nAhora bien se proceder√° a realizar el contraste de Johansen para el caso sin constante.\n\n\nTabla¬†2: Contraste de Cointegraci√≥n de Johansen\n\n\n\n\n\n\n\n\n\nPa√≠s\nCointegraci√≥n\n\\(p\\)-valor asint.\nboot \\(p\\)-valor\nrango\n\n\n\n\nBolivia\nsi\n0,041\n0,089\n1\n\n\nBrasil\nsi\n0,345\n0,431\n1\n\n\nChile\nsi\n0,077\n0,131\n1\n\n\nColombia\nsi\n0,571\n0,814\n1\n\n\nCosta Rica\nsi\n0,297\n0,639\n1\n\n\nEcuador\nno\n0,018\n0,01\n1\n\n\nGuatemala\nsi\n0,602\n0,906\n1\n\n\nHonduras\nno\n0,082\n0,085\n0\n\n\nM√©xico\nno\n0,144\n0,307\n0\n\n\nNicaragua\nno\n0,063\n0,079\n0\n\n\nPanam√°\nsi\n0,247\n0,354\n1\n\n\nParaguay\nsi\n0,026\n0,055\n1\n\n\nPer√∫\nsi\n0,333\n0,499\n1\n\n\nR. Dominicana\nsi\n0,139\n0,379\n1\n\n\n\n\nEn la tabla Tabla¬†2 se ha realizado el contraste de cointegraci√≥n de Johansen entre las series tanto de Renta (PIB) como de Consumo (Consumo familiar) para cada pa√≠s. Es as√≠ que de manera general tenemos que para cada pa√≠s.\nDada la hip√≥tesis nula de que el rango de la matriz de cointegraci√≥n es \\(0\\) frente a la alternativa de que el rango de cointegraci√≥n es \\(1\\). Entonces tenemos que para Honduras, M√©xico, Nicaragua, las series de consumo y renta no est√°n cointegradas pues para un nivel de significancia \\(alpha=0.05\\) no se rechaza la hip√≥tesis nula de que el rango de la matriz de cointegraci√≥n es \\(0\\). Por otro lado, para el resto de pa√≠ses menos Ecuador se tiene que dada la hip√≥tesis nula rango de la matriz de cointegraci√≥n es \\(1\\) frente a la alternativa rango de la matriz de cointegraci√≥n es \\(2\\), para un nivel de significancia \\(\\alpha=0.05\\) no se rechaza la hip√≥tesis nula de que el rango de cointegraci√≥n es \\(1\\) con valores \\(p\\) dados en la tabla Tabla¬†2. Finalmente, para Ecuador se tienen que para un nivel de significancia \\(\\alpha=0.05\\) Se rechaza la hip√≥tesis nula de que el rango de cointegraci√≥n es \\(1\\).\n\n\nTabla¬†3: Contraste de no Causalidad de Dumitrescu-Hurlin entre Consumo y Renta\n\n\nPa√≠s\n\\(Y\\) no causa \\(C\\)\np-valor\ncausalidad\n\n\n\n\nBolivia\nsi\n0,6174\nno\n\n\nBrasil\nno\n0,0002\nsi\n\n\nChile\nno\n0,0027\nsi\n\n\nColombia\nsi\n0,9225\nno\n\n\nCosta Rica\nsi\n0,2856\nno\n\n\nEcuador\nno\n0,0172\nsi\n\n\nGuatemala\nno\n0,0001\nsi\n\n\nHonduras\nsi\n0,6704\nno\n\n\nM√©xico\nsi\n0,4979\nno\n\n\nNicaragua\nsi\n0,3064\nno\n\n\nPanam√°\nsi\n0,5101\nno\n\n\nParaguay\nsi\n0,8212\nno\n\n\nPer√∫\nno\n0,0002\nsi\n\n\nR. Dominicana\nsi\n0,7106\nno\n\n\n\n\nEn la tabla Tabla¬†3 se ha realizado un resumen del contraste de no causalidad de Dumitrescu-Hurlin para cada modelo de consumo de cada pa√≠s. Dada la hip√≥tesis nula de \\(Y\\) no causa \\(X\\) frente a la hip√≥tesis alternativa \\(Y\\) causa \\(X\\). tenemos que para los siguientes pa√≠ses: Brasil, Chile, Ecuador, Guatemala, Per√∫. Para un nivel de significancia \\(\\alpha=0.05\\) se rechaza la hip√≥tesis nula de no causalidad con valores \\(p\\) dados en la tabla Tabla¬†3. Para el resto de pa√≠ses no se rechaza la hip√≥tesis nula de no causalidad."
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#resultados",
    "href": "proyects/Tesis_JXBS/index.html#resultados",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Resultados",
    "text": "Resultados\nEn la tabla Tabla¬†1 se ha evidenciado que tanto las series de Consumo as√≠ como las series De Renta poseen una ra√≠z unitaria es decir son series integradas de orden uno. Adem√°s se observa que para la mayor√≠a de pa√≠ses el valor \\(p\\) es mayor a \\(0.95\\) es decir tenemos una gran certeza de que nuestras series son no estacionarias, lo cual nos permite realizar el an√°lisis sobre el modelo Ecuaci√≥n¬†15.\nAhora bien, una vez tenemos que las series son no estacionarias en la tabla Tabla¬†2 se ha realizado la prueba de cointegraci√≥n de Johansen para el caso sin constante. De donde, se ha obtenido que los pa√≠ses de Ecuador, Honduras, M√©xico, y Nicaragua no se encuentra cointegrados esto puede ser debido a que para estos pa√≠ses las series tanto de Consumo y Renta al momento de analizar las intervenciones para esta se evidencio que las series tienen ciertas irregularidades que si bien se esperaba que quedaran enterradas en las innovaciones, estas no pueden absorberlas del todo.\nFinalmente, para los pa√≠ses cuyo modelo si esta cointegrado se ha realizado un contraste de causalidad viendo a estos datos como un panel de series apiladas. Es as√≠ que se ha obtenido que para pa√≠ses cuyas intervenciones han sido absorbidas por las innovaciones el modelo propuesto en este trabajo ayuda a mejorar la predicci√≥n del consumo."
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#conclusiones",
    "href": "proyects/Tesis_JXBS/index.html#conclusiones",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Conclusiones",
    "text": "Conclusiones\nDado que uno de los objetivos de este trabajo fue revisar los modelos de ciclo de vida y funciones de consumo desde el punto de vista neocl√°sico, para los cuales si bien el lineamiento esta bastante acertado, en este trabajo se ha propuesto un modelo que mejora el modelo neocl√°sico. Esto se evidencia para pa√≠ses en los que los datos no tienen intervenciones de gran impacto es decir que su perturbaciones pueden ser absorbidas por las innovaciones al instante \\(t+1\\). El modelo Ecuaci√≥n¬†15 ayuda a predecir de manera mas eficiente el Consumo; debido a que para estos pa√≠ses el tener informaci√≥n acerca de la renta en cada instante ayuda a predecir el consumo al instante \\(t+1\\). Por otro lado para los pa√≠ses, para los cuales las innovaciones causan impactos demasiado grandes, no se puede decir con certeza que el modelo propuesto no seria bueno. Puesto que, si se lograra mitigar los mencionados impactos en el tratamiento de la data podr√≠a darse cualquier resultado. Desde un punto de vista econom√©trico el modelo propuesto bajo las condiciones impuestas ayuda a establecer una relaci√≥n entre la Renta y el Consumo esta relaci√≥n es del tipo causal de Granger."
  },
  {
    "objectID": "proyects/Tesis_JXBS/index.html#footnotes",
    "href": "proyects/Tesis_JXBS/index.html#footnotes",
    "title": "Estudio Te√≥rico del Comportamiento del Consumo en Latin√°merica y Caribe (Resumen)",
    "section": "Notas",
    "text": "Notas\n\n\nUna ecuaci√≥n de Euler del consumo, a grandes rasgos, es una condici√≥n matem√°tica que describe el comportamiento de una senda √≥ptima de consumo bajo los supuestos de elecci√≥n intertemporal, expectativas racionales y agente representativo, entre otros, (Parker 2007)‚Ü©Ô∏é\nEntonces se puede considerar como la varianza cruzada del consumo para una cohorte de individuos.‚Ü©Ô∏é\n\\(u_t\\) innovaciones en la renta permanente‚Ü©Ô∏é\nPor el TCL, \\(\\sum u_t \\overset{d}{\\sim} Normal\\) con \\(u_t\\) independientes , bajo supuestos de regularidad incluso si \\(u_t \\not\\sim Normal\\)‚Ü©Ô∏é\nAl igual que con otros documentos, rechazan en√©rgicamente la suposici√≥n de una perfecta distribuci√≥n del riesgo.‚Ü©Ô∏é\nSeg√∫n (Orazio P. Attanasio y Weber 2010) esto parece indicar que, de alguna manera, en altas frecuencias los choques salariales son absorbidos y no se reflejan en el consumo.‚Ü©Ô∏é\nPor ejemplo, es posible que el ingreso est√© dado por la tasa de salario multiplicada por el n√∫mero de horas trabajadas, donde el n√∫mero de horas es uno de los componentes de \\(z\\)‚Ü©Ô∏é\nEsta simple restricci√≥n impone limitaciones cuantitativamente importantes a la capacidad de suavizar el consumo‚Ü©Ô∏é\nTRAMO significa ‚ÄúTime series Regression with ARIMA noise, Missing values and Outliers‚Äù y SEATS ‚ÄúSignal Extraction in ARIMA Time Series‚Äù. Estos programas (que normalmente se usan juntos) han sido desarrollados por V√≠ctor G√≥mez y Agust√≠n Maravall del Banco de Espa√±a.‚Ü©Ô∏é\nDado el fen√≥meno del ni√±o (1995) el cual fue uno de los desastres naturales mas grandes que ha impactado al Ecuador seria el principio de la bola de nieve que desencadenar√≠a en 1999 con el ya tan conocido ‚ÄúFeriado Bancario‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "certific.html",
    "href": "certific.html",
    "title": "Certificados",
    "section": "",
    "text": "Ordenar por\n       Por defecto\n         \n          T√≠tulo\n        \n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - M√°s reciente\n        \n         \n          Autor/a\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nR para data scientist avanzado\n\n\n\nR\n\n\nData Science\n\n\ntidyverse\n\n\nSeries Temporales\n\n\nArboles de decisi√≥n\n\n\n\n\n\n\n\n\n\n\n27 oct 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython para data science y big data esencial\n\n\n\nPython\n\n\nData Science\n\n\nBig Data\n\n\npandas\n\n\nPySpark\n\n\nsklearn\n\n\n\n\n\n\n\n\n\n\n24 oct 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamentos profesionales del an√°lisis de datos, por Microsfot y LinkedIn\n\n\n\nAnal√≠tica de datos\n\n\nCiencia de datos\n\n\n\n\n\n\n\n\n\n\n16 oct 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAprende data science Conceptos b√°sicos\n\n\n\nCiencia de datos\n\n\n\n\n\n\n\n\n\n\n12 oct 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducci√≥n a las habilidades profesionales en an√°lisis de datos\n\n\n\nAn√°lisis de datos\n\n\nAnal√≠tica de datos\n\n\nAptitudes para carreras tecnologicas\n\n\nExcel\n\n\nPower BI\n\n\n\n\n\n\n\n\n\n\n5 oct 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso Completo de Data Science en Python Desde Cero [2023]\n\n\n\nPython\n\n\nData Science\n\n\npandas\n\n\nsklearn\n\n\nstatsmodels\n\n\nBeautifulSoup\n\n\n\n\n\n\n\n\n\n\n22 jun 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso Power BI\n\n\n\nPower BI\n\n\nBussiness Intelligence\n\n\n\n\n\n\n\n\n\n\n25 may 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso Tableau Desktop\n\n\n\nTableau\n\n\nBussiness Intelligence\n\n\n\n\n\n\n\n\n\n\n19 may 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso PHP y MySQL\n\n\n\nMySQL\n\n\nPHP\n\n\n\n\n\n\n\n\n\n\n16 may 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso Pron√≥stico Ventas\n\n\n\nPron√≥sticos Ventas\n\n\nExcel\n\n\n\n\n\n\n\n\n\n\n16 abr 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso te√≥rico pr√°ctico El ambiente de Programaci√≥n R en el √°mbito de la investigaci√≥n cient√≠fica\n\n\n\nR\n\n\nData Science\n\n\ntidyverse\n\n\ngit\n\n\nRmarkdown\n\n\n\n\n\n\n\n\n\n\n3 sept 2020\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "certificados/25-05-2023_Curso_power-BI/index.html",
    "href": "certificados/25-05-2023_Curso_power-BI/index.html",
    "title": "Curso Power BI",
    "section": "",
    "text": "Curso Power BI"
  },
  {
    "objectID": "certificados/16-05-2023-Curso_de_PHP-MySQL/index.html",
    "href": "certificados/16-05-2023-Curso_de_PHP-MySQL/index.html",
    "title": "Curso PHP y MySQL",
    "section": "",
    "text": "Curso PHP y MySQL"
  },
  {
    "objectID": "certificados/16-04-2023-Pronostico-Ventas/index.html",
    "href": "certificados/16-04-2023-Pronostico-Ventas/index.html",
    "title": "Curso Pron√≥stico Ventas",
    "section": "",
    "text": "Curso Prono√≥stico Ventas"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "",
    "text": "import numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\npd.options.display.max_columns=None #para que se despliegue todas las columnas\n\nimport warnings \nwarnings.filterwarnings('ignore')\nfrom matplotlib import cm\nc4=cm.get_cmap('Set3')"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#frecuencia-de-los-tipos-de-acciedentes",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#frecuencia-de-los-tipos-de-acciedentes",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Frecuencia de los tipos de acciedentes",
    "text": "Frecuencia de los tipos de acciedentes\n\nsb.countplot(x=df['Collision Type'],palette='Set3')\nplt.ylabel('Frecuencia')\nplt.xticks(rotation=65)\nplt.title(\"Frecuencia de tipos de Accidentes\")\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nObservamos que existe una mayor cantidad de accidentes entre dos veh√≠culos, por otro lado la cantidad de accidentes de bicicletas es la menor."
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#accidentes-ocurridos-entre-semana-vs-fin-de-semana",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#accidentes-ocurridos-entre-semana-vs-fin-de-semana",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Accidentes ocurridos entre semana vs fin de semana",
    "text": "Accidentes ocurridos entre semana vs fin de semana\n\nsb.countplot(x=df['Weekend?'],palette='Accent')\nplt.ylabel('Frecuencia')\nplt.xticks(rotation=65)\nplt.title(\"Entre semana vs Fin de semana\")\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nObservamos que el Fin de semana es cuando mas ocurren accidentes."
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#porcentaje-de-lesiones-por-categoria",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#porcentaje-de-lesiones-por-categoria",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Porcentaje de lesiones por Categoria",
    "text": "Porcentaje de lesiones por Categoria\n\nles_val=df['Injury Type'].value_counts()\nles_val\n\nInjury Type\nNo injury/unknown     41603\nNon-incapacitating    11136\nIncapacitating         1089\nFatal                   115\nName: count, dtype: int64\n\n\n\nplt.pie(les_val,labels=les_val.index,startangle=30,shadow=True,autopct='%1.1f%%',rotatelabels=30,explode=(0.1,0.1,0.1,0.1),colors=[c4(0.9),c4(0.2),c4(0.3),c4(0.6)])\nplt.title('Porcentaje de lesiones por Categoria')\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nObservamos que el \\(0.2\\%\\) de accidentes son Fatales. Por otro lado algo que ser√≠a de mucho interes saber de cuantos accidentes no se conoce la lesi√≥n ocasionada puesto que la probabilidad de no tener lesiones es muy baja."
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#motivo-mas-comun-por-el-cual-suceden-accidentes",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#motivo-mas-comun-por-el-cual-suceden-accidentes",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Motivo mas comun por el cual suceden accidentes",
    "text": "Motivo mas comun por el cual suceden accidentes\nPrimero indagaremos cuantos Factores Primarios existen en la data\n\ndf['Primary Factor'].nunique()\n\n55\n\n\nDado que existen \\(55\\) Factores Primarios nos quedaremos con el top 20\n\npfdf=df['Primary Factor'].value_counts().head(20)\n\n\nfig=plt.figure(figsize=(10,10))\naxis=fig.add_axes([1,1,1,1])\nsb.swarmplot(x=pfdf,y=pfdf.index,ax=axis)\nfor i,j in enumerate(pfdf):\n  axis.text(j,i,j)\nplt.xlabel('Ocurrencia')\nplt.title('Motivos principales por los que ocurren accidentes')\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#top-30-lugares-mas-frecuente-donde-ocurren-accidentes",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#top-30-lugares-mas-frecuente-donde-ocurren-accidentes",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Top 30 lugares mas frecuente donde ocurren accidentes",
    "text": "Top 30 lugares mas frecuente donde ocurren accidentes\n\nldf=df['Reported_Location'].value_counts().head(30)\n\n\nfig1=plt.figure()\naxis1=fig1.add_axes([1,1,1,1])\nsb.barplot(x=ldf,y=ldf.index,ax=axis1,palette=\"viridis\")\nfor i,j in enumerate(ldf):\n  axis1.text(j,i,j,va='top')\naxis1.set_xlabel('Frecuencia')\naxis1.set_title('Lugares con mayor frecuencia de Accidentes')\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#tipos-de-colisiones-en-diferentes-a√±os",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#tipos-de-colisiones-en-diferentes-a√±os",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Tipos de Colisiones en diferentes a√±os",
    "text": "Tipos de Colisiones en diferentes a√±os\n\na√±os=df.groupby('Year')\nkeys=a√±os.groups.keys()\n\n\ninfobox=[]\nfor i in range(2003,2016):\n  infobox.append(a√±os.get_group(i)['Collision Type'].value_counts())\n\n\nc2=cm.get_cmap('terrain')\n\n\nfrom IPython.display import display, Markdown\n\nColisiones por A√±o\n\n2003200420052006200720082009201020112012201320142015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2003",
    "text": "2003"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-1",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-1",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2004",
    "text": "2004"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-2",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-2",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2005",
    "text": "2005"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-3",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-3",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2006",
    "text": "2006"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-4",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-4",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2007",
    "text": "2007"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-5",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-5",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2008",
    "text": "2008"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-6",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-6",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2009",
    "text": "2009"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-7",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-7",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2010",
    "text": "2010"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-8",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-8",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2011",
    "text": "2011"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-9",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-9",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2012",
    "text": "2012"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-10",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-10",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2013",
    "text": "2013"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-11",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-11",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2014",
    "text": "2014"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-12",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#section-12",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "2015",
    "text": "2015\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n:::"
  },
  {
    "objectID": "posts/2024-1-13-Accidentes automovilisticos/index.html#gr√°fico-dinamico",
    "href": "posts/2024-1-13-Accidentes automovilisticos/index.html#gr√°fico-dinamico",
    "title": "Accidentes automovilisticos Conjunto de datos EDA",
    "section": "Gr√°fico Dinamico",
    "text": "Gr√°fico Dinamico\n\nimport plotly.express as px\n\n\npx.histogram(df,x='Collision Type', \nanimation_frame=df['Year'].sort_values(ascending=True),\ncolor='Collision Type', title='Accidentes por Tipo de Colisi√≥n'\n)"
  },
  {
    "objectID": "contacto.html",
    "href": "contacto.html",
    "title": "Contactos",
    "section": "",
    "text": "0997868351"
  },
  {
    "objectID": "contacto.html#linkedin-jxbsjb",
    "href": "contacto.html#linkedin-jxbsjb",
    "title": "Contactos",
    "section": "LinkedIn : jxbsjb",
    "text": "LinkedIn : jxbsjb"
  },
  {
    "objectID": "contacto.html#email-joelburbanooutlook.com",
    "href": "contacto.html#email-joelburbanooutlook.com",
    "title": "Contactos",
    "section": "Email : joelburbano@outlook.com",
    "text": "Email : joelburbano@outlook.com"
  },
  {
    "objectID": "contacto.html#linkedin-fa-linkedin-square-jxbsjb",
    "href": "contacto.html#linkedin-fa-linkedin-square-jxbsjb",
    "title": "Contactos",
    "section": "LinkedIn  jxbsjb",
    "text": "LinkedIn  jxbsjb"
  },
  {
    "objectID": "contacto.html#whatsapp",
    "href": "contacto.html#whatsapp",
    "title": "Contactos",
    "section": "",
    "text": "0997868351"
  },
  {
    "objectID": "contacto.html#whatsapp-r-fanamewhatsapp",
    "href": "contacto.html#whatsapp-r-fanamewhatsapp",
    "title": "Contactos",
    "section": "",
    "text": "0997868351"
  }
]